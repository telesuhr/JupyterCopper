{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMEéŠ…å…ˆç‰© éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "\n",
    "## æ¦‚è¦\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆM1-M2ã€M2-M3ã€M3-M4ï¼‰ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹æ€§ã‚’è©³ç´°ã«åˆ†æã—ã€GARCHç³»ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒªã‚¹ã‚¯ç‰¹æ€§ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "### åˆ†æç›®æ¨™\n",
    "- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®æ¤œå‡º\n",
    "- GARCHç³»ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬\n",
    "- ãƒªã‚¹ã‚¯æŒ‡æ¨™ï¼ˆVaRã€ESï¼‰ã®è¨ˆç®—\n",
    "- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ã®ç‰¹å®š\n",
    "\n",
    "### æœŸå¾…ã•ã‚Œã‚‹æˆæœ\n",
    "- å„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å‹•å­¦ã®ç†è§£\n",
    "- å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ã®å–å¼•æˆ¦ç•¥ã®åŸºç›¤\n",
    "- ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆç”¨ã®ãƒªã‚¹ã‚¯ã‚·ãƒŠãƒªã‚ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "from arch import arch_model\n",
    "from arch.unitroot import ADF\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ãƒªã‚¹ã‚¯è¨ˆç®—\n",
    "from scipy.stats import norm, t\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†\n",
    "def get_db_connection():\n",
    "    \"\"\"PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æ¥ç¶šã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        engine = create_engine('postgresql://Yusuke@localhost:5432/lme_copper_db')\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—\"\"\"\n",
    "    engine = get_db_connection()\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        trade_date,\n",
    "        contract_month,\n",
    "        close_price\n",
    "    FROM lme_copper_futures \n",
    "    WHERE contract_month IN (1, 2, 3, 4)\n",
    "        AND close_price IS NOT NULL\n",
    "        AND close_price > 0\n",
    "    ORDER BY trade_date, contract_month\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql(query, engine)\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    \n",
    "    # ãƒ”ãƒœãƒƒãƒˆã—ã¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—\n",
    "    pivot_df = df.pivot(index='trade_date', columns='contract_month', values='close_price')\n",
    "    pivot_df.columns = [f'M{int(col)}' for col in pivot_df.columns]\n",
    "    \n",
    "    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—\n",
    "    spreads_df = pd.DataFrame(index=pivot_df.index)\n",
    "    spreads_df['M1_M2_spread'] = pivot_df['M1'] - pivot_df['M2']\n",
    "    spreads_df['M2_M3_spread'] = pivot_df['M2'] - pivot_df['M3']\n",
    "    spreads_df['M3_M4_spread'] = pivot_df['M3'] - pivot_df['M4']\n",
    "    \n",
    "    # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—\n",
    "    spreads_df['M1_M2_return'] = spreads_df['M1_M2_spread'].pct_change()\n",
    "    spreads_df['M2_M3_return'] = spreads_df['M2_M3_spread'].pct_change()\n",
    "    spreads_df['M3_M4_return'] = spreads_df['M3_M4_spread'].pct_change()\n",
    "    \n",
    "    # å¯¾æ•°å·®åˆ†ï¼ˆå¯¾æ•°ãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã‚‚è¨ˆç®—\n",
    "    spreads_df['M1_M2_log_return'] = np.log(spreads_df['M1_M2_spread'].abs()).diff()\n",
    "    spreads_df['M2_M3_log_return'] = np.log(spreads_df['M2_M3_spread'].abs()).diff()\n",
    "    spreads_df['M3_M4_log_return'] = np.log(spreads_df['M3_M4_spread'].abs()).diff()\n",
    "    \n",
    "    return spreads_df.dropna()\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "spreads_data = load_and_prepare_data()\n",
    "print(f\"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(spreads_data):,} ãƒ¬ã‚³ãƒ¼ãƒ‰\")\n",
    "print(f\"ğŸ“… åˆ†ææœŸé–“: {spreads_data.index.min()} ï½ {spreads_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®åŸºæœ¬åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_basic_volatility(df):\n",
    "    \"\"\"åŸºæœ¬çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    \n",
    "    print(\"ğŸ“Š åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±è¨ˆ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    volatility_stats = pd.DataFrame()\n",
    "    \n",
    "    for col in return_columns:\n",
    "        spread_name = col.replace('_return', '').replace('_', '-')\n",
    "        returns = df[col].dropna()\n",
    "        \n",
    "        # åŸºæœ¬çµ±è¨ˆé‡\n",
    "        volatility_stats[spread_name] = [\n",
    "            returns.std() * 100,                    # æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ%ï¼‰\n",
    "            returns.std() * np.sqrt(252) * 100,     # å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ%ï¼‰\n",
    "            returns.skew(),                         # æ­ªåº¦\n",
    "            returns.kurtosis(),                     # å°–åº¦ï¼ˆè¶…éå°–åº¦ï¼‰\n",
    "            (returns.abs() > 2*returns.std()).sum(), # 2Ïƒè¶…éå›æ•°\n",
    "            (returns.abs() > 3*returns.std()).sum(), # 3Ïƒè¶…éå›æ•°\n",
    "            len(returns)                            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "        ]\n",
    "    \n",
    "    volatility_stats.index = [\n",
    "        'æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£(%)', 'å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£(%)', 'æ­ªåº¦', 'å°–åº¦',\n",
    "        '2Ïƒè¶…éå›æ•°', '3Ïƒè¶…éå›æ•°', 'ãƒ‡ãƒ¼ã‚¿æ•°'\n",
    "    ]\n",
    "    \n",
    "    print(volatility_stats.round(4))\n",
    "    \n",
    "    # æ­£è¦æ€§æ¤œå®š\n",
    "    print(\"\\nğŸ”¬ æ­£è¦æ€§æ¤œå®šçµæœ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for col in return_columns:\n",
    "        spread_name = col.replace('_return', '').replace('_', '-')\n",
    "        returns = df[col].dropna()\n",
    "        \n",
    "        # Jarque-Beraæ¤œå®š\n",
    "        jb_stat, jb_p = stats.jarque_bera(returns)\n",
    "        \n",
    "        # Shapiro-Wilkæ¤œå®šï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™ï¼‰\n",
    "        if len(returns) <= 5000:\n",
    "            sw_stat, sw_p = stats.shapiro(returns)\n",
    "        else:\n",
    "            sw_stat, sw_p = stats.shapiro(returns.sample(5000, random_state=42))\n",
    "        \n",
    "        print(f\"{spread_name}:\")\n",
    "        print(f\"  Jarque-Bera: çµ±è¨ˆé‡={jb_stat:.4f}, på€¤={jb_p:.4f}\")\n",
    "        print(f\"  Shapiro-Wilk: çµ±è¨ˆé‡={sw_stat:.4f}, på€¤={sw_p:.4f}\")\n",
    "        print(f\"  çµæœ: {'éæ­£è¦åˆ†å¸ƒ' if jb_p < 0.05 else 'æ­£è¦åˆ†å¸ƒã®å¯èƒ½æ€§'}\")\n",
    "    \n",
    "    return volatility_stats\n",
    "\n",
    "# åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æå®Ÿè¡Œ\n",
    "vol_stats = analyze_basic_volatility(spreads_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volatility_analysis(df):\n",
    "    \"\"\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æã®å¯è¦–åŒ–\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒªã‚¿ãƒ¼ãƒ³ã®æ™‚ç³»åˆ—',\n",
    "            'ãƒªã‚¿ãƒ¼ãƒ³åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰',\n",
    "            'ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ30æ—¥ï¼‰',\n",
    "            'Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦åˆ†å¸ƒã¨ã®æ¯”è¼ƒï¼‰',\n",
    "            'çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³ã®è‡ªå·±ç›¸é–¢',\n",
    "            'ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°'\n",
    "        ),\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    # 1. ãƒªã‚¿ãƒ¼ãƒ³ã®æ™‚ç³»åˆ—\n",
    "    for i, (col, name, color) in enumerate(zip(return_columns, spread_names, colors)):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=df[col] * 100,  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›\n",
    "                name=f'{name}ãƒªã‚¿ãƒ¼ãƒ³',\n",
    "                line=dict(color=color, width=0.8),\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. ãƒªã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ\n",
    "    for i, (col, name, color) in enumerate(zip(return_columns, spread_names, colors)):\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=df[col] * 100,\n",
    "                name=f'{name}åˆ†å¸ƒ',\n",
    "                nbinsx=50,\n",
    "                opacity=0.7,\n",
    "                marker_color=color\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "    for i, (col, name, color) in enumerate(zip(return_columns, spread_names, colors)):\n",
    "        rolling_vol = df[col].rolling(window=30).std() * np.sqrt(252) * 100\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=rolling_vol,\n",
    "                name=f'{name}ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "                line=dict(color=color, width=1.5)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆM1-M2ã®ã¿ï¼‰\n",
    "    from scipy.stats import probplot\n",
    "    returns_clean = df['M1_M2_return'].dropna()\n",
    "    theoretical_q, sample_q = probplot(returns_clean, dist=\"norm\")\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=theoretical_q,\n",
    "            y=sample_q,\n",
    "            mode='markers',\n",
    "            name='M1-M2 Q-Q',\n",
    "            marker=dict(color='blue', size=3)\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # ç†è«–ç·š\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[theoretical_q.min(), theoretical_q.max()],\n",
    "            y=[sample_q.min(), sample_q.max()],\n",
    "            mode='lines',\n",
    "            name='ç†è«–ç·š',\n",
    "            line=dict(color='red', dash='dash')\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # 5. çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³ã®è‡ªå·±ç›¸é–¢ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ¤œå‡ºï¼‰\n",
    "    abs_returns = df['M1_M2_return'].abs().dropna()\n",
    "    lags = range(1, 21)\n",
    "    autocorrs = [abs_returns.autocorr(lag=lag) for lag in lags]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(lags),\n",
    "            y=autocorrs,\n",
    "            name='M1-M2çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³è‡ªå·±ç›¸é–¢',\n",
    "            marker_color='lightblue'\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # æœ‰æ„æ€§ã®é–¾å€¤ç·šï¼ˆ5%æ°´æº–ï¼‰\n",
    "    n = len(abs_returns)\n",
    "    threshold = 1.96 / np.sqrt(n)\n",
    "    fig.add_hline(y=threshold, line_dash=\"dash\", line_color=\"red\", \n",
    "                 line_width=1, row=3, col=1)\n",
    "    fig.add_hline(y=-threshold, line_dash=\"dash\", line_color=\"red\", \n",
    "                 line_width=1, row=3, col=1)\n",
    "    \n",
    "    # 6. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®å¯è¦–åŒ–\n",
    "    squared_returns = (df['M1_M2_return'] ** 2).dropna()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[:len(squared_returns)],\n",
    "            y=squared_returns * 10000,  # ãƒ™ãƒ¼ã‚·ã‚¹ãƒã‚¤ãƒ³ãƒˆ\n",
    "            name='M1-M2 äºŒä¹—ãƒªã‚¿ãƒ¼ãƒ³',\n",
    "            line=dict(color='purple', width=1),\n",
    "            fill='tonexty',\n",
    "            fillcolor='rgba(128,0,128,0.3)'\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=1000,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    fig.update_yaxes(title_text=\"ãƒªã‚¿ãƒ¼ãƒ³ (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"é »åº¦\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"ãƒªã‚¿ãƒ¼ãƒ³ (%)\", row=1, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"ã‚µãƒ³ãƒ—ãƒ«åˆ†ä½æ•°\", row=2, col=2)\n",
    "    fig.update_xaxes(title_text=\"ç†è«–åˆ†ä½æ•°\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"è‡ªå·±ç›¸é–¢\", row=3, col=1)\n",
    "    fig.update_xaxes(title_text=\"ãƒ©ã‚°\", row=3, col=1)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"äºŒä¹—ãƒªã‚¿ãƒ¼ãƒ³ (bp)\", row=3, col=2)\n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=3, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æãƒãƒ£ãƒ¼ãƒˆ\n",
    "vol_chart = plot_volatility_analysis(spreads_data)\n",
    "vol_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "os.makedirs('../generated_images', exist_ok=True)\n",
    "vol_chart.write_image('../generated_images/adjacent_spreads_volatility_analysis.png', \n",
    "                     width=1200, height=1000, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARCHåŠ¹æœã®æ¤œå®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_arch_effects(df):\n",
    "    \"\"\"ARCHåŠ¹æœï¼ˆæ¡ä»¶ä»˜ãåˆ†æ•£ä¸å‡ä¸€æ€§ï¼‰ã®æ¤œå®š\"\"\"\n",
    "    from arch.unitroot import DFGLS\n",
    "    from statsmodels.stats.diagnostic import het_arch\n",
    "    \n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    print(\"ğŸ”¬ ARCHåŠ¹æœæ¤œå®šçµæœ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    arch_test_results = {}\n",
    "    \n",
    "    for col, name in zip(return_columns, spread_names):\n",
    "        returns = df[col].dropna() * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›\n",
    "        \n",
    "        print(f\"\\n{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        \n",
    "        # 1. åŸºæœ¬çµ±è¨ˆé‡\n",
    "        print(f\"  ãƒ‡ãƒ¼ã‚¿æ•°: {len(returns):,}\")\n",
    "        print(f\"  å¹³å‡: {returns.mean():.4f}%\")\n",
    "        print(f\"  æ¨™æº–åå·®: {returns.std():.4f}%\")\n",
    "        \n",
    "        # 2. å®šå¸¸æ€§æ¤œå®šï¼ˆADFï¼‰\n",
    "        adf_result = adfuller(returns)\n",
    "        print(f\"  ADFæ¤œå®š: çµ±è¨ˆé‡={adf_result[0]:.4f}, på€¤={adf_result[1]:.4f}\")\n",
    "        print(f\"    çµæœ: {'å®šå¸¸' if adf_result[1] < 0.05 else 'éå®šå¸¸'}\")\n",
    "        \n",
    "        # 3. Ljung-Boxæ¤œå®šï¼ˆç³»åˆ—ç›¸é–¢ï¼‰\n",
    "        try:\n",
    "            lb_result = acorr_ljungbox(returns, lags=10, return_df=True)\n",
    "            lb_pvalue = lb_result['lb_pvalue'].iloc[-1]  # 10ãƒ©ã‚°ã®çµæœ\n",
    "            print(f\"  Ljung-Boxæ¤œå®š(10ãƒ©ã‚°): på€¤={lb_pvalue:.4f}\")\n",
    "            print(f\"    çµæœ: {'ç³»åˆ—ç›¸é–¢ã‚ã‚Š' if lb_pvalue < 0.05 else 'ç³»åˆ—ç›¸é–¢ãªã—'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Ljung-Boxæ¤œå®š: ã‚¨ãƒ©ãƒ¼ - {e}\")\n",
    "            lb_pvalue = np.nan\n",
    "        \n",
    "        # 4. ARCH-LMæ¤œå®šï¼ˆæ¡ä»¶ä»˜ãåˆ†æ•£ä¸å‡ä¸€æ€§ï¼‰\n",
    "        try:\n",
    "            # è¤‡æ•°ã®ãƒ©ã‚°ã§æ¤œå®š\n",
    "            for lag in [5, 10, 15]:\n",
    "                lm_stat, lm_pvalue, _, _ = het_arch(returns, nlags=lag)\n",
    "                print(f\"  ARCH-LMæ¤œå®š({lag}ãƒ©ã‚°): çµ±è¨ˆé‡={lm_stat:.4f}, på€¤={lm_pvalue:.4f}\")\n",
    "                if lag == 10:  # 10ãƒ©ã‚°ã®çµæœã‚’ä¿å­˜\n",
    "                    main_arch_pvalue = lm_pvalue\n",
    "            \n",
    "            print(f\"    çµæœ: {'ARCHåŠ¹æœã‚ã‚Š' if main_arch_pvalue < 0.05 else 'ARCHåŠ¹æœãªã—'}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ARCH-LMæ¤œå®š: ã‚¨ãƒ©ãƒ¼ - {e}\")\n",
    "            main_arch_pvalue = np.nan\n",
    "        \n",
    "        # 5. çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³ã®è‡ªå·±ç›¸é–¢æ¤œå®š\n",
    "        abs_returns = returns.abs()\n",
    "        try:\n",
    "            abs_lb_result = acorr_ljungbox(abs_returns, lags=10, return_df=True)\n",
    "            abs_lb_pvalue = abs_lb_result['lb_pvalue'].iloc[-1]\n",
    "            print(f\"  çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³Ljung-Boxæ¤œå®š: på€¤={abs_lb_pvalue:.4f}\")\n",
    "            print(f\"    çµæœ: {'ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚ã‚Š' if abs_lb_pvalue < 0.05 else 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãªã—'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  çµ¶å¯¾ãƒªã‚¿ãƒ¼ãƒ³Ljung-Boxæ¤œå®š: ã‚¨ãƒ©ãƒ¼ - {e}\")\n",
    "            abs_lb_pvalue = np.nan\n",
    "        \n",
    "        # çµæœã‚’ä¿å­˜\n",
    "        arch_test_results[name] = {\n",
    "            'data_count': len(returns),\n",
    "            'mean': returns.mean(),\n",
    "            'std': returns.std(),\n",
    "            'adf_statistic': adf_result[0],\n",
    "            'adf_pvalue': adf_result[1],\n",
    "            'is_stationary': adf_result[1] < 0.05,\n",
    "            'ljungbox_pvalue': lb_pvalue,\n",
    "            'has_serial_correlation': lb_pvalue < 0.05 if not np.isnan(lb_pvalue) else None,\n",
    "            'arch_lm_pvalue': main_arch_pvalue,\n",
    "            'has_arch_effects': main_arch_pvalue < 0.05 if not np.isnan(main_arch_pvalue) else None,\n",
    "            'abs_ljungbox_pvalue': abs_lb_pvalue,\n",
    "            'has_volatility_clustering': abs_lb_pvalue < 0.05 if not np.isnan(abs_lb_pvalue) else None\n",
    "        }\n",
    "    \n",
    "    return arch_test_results\n",
    "\n",
    "# ARCHåŠ¹æœæ¤œå®šå®Ÿè¡Œ\n",
    "arch_results = test_arch_effects(spreads_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GARCHãƒ¢ãƒ‡ãƒ«ã®æ¨å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_garch_models(df):\n",
    "    \"\"\"GARCHç³»ãƒ¢ãƒ‡ãƒ«ã®æ¨å®š\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    garch_models = {}\n",
    "    \n",
    "    print(\"ğŸ“ˆ GARCHãƒ¢ãƒ‡ãƒ«æ¨å®šçµæœ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for col, name in zip(return_columns, spread_names):\n",
    "        returns = df[col].dropna() * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›\n",
    "        \n",
    "        print(f\"\\n{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        \n",
    "        models_to_estimate = {\n",
    "            'GARCH(1,1)': arch_model(returns, vol='Garch', p=1, q=1),\n",
    "            'EGARCH(1,1)': arch_model(returns, vol='EGARCH', p=1, q=1),\n",
    "            'GJR-GARCH(1,1)': arch_model(returns, vol='GARCH', p=1, o=1, q=1)\n",
    "        }\n",
    "        \n",
    "        model_results = {}\n",
    "        \n",
    "        for model_name, model in models_to_estimate.items():\n",
    "            try:\n",
    "                # ãƒ¢ãƒ‡ãƒ«æ¨å®š\n",
    "                result = model.fit(disp='off', show_warning=False)\n",
    "                \n",
    "                # AIC/BICè¨ˆç®—\n",
    "                aic = result.aic\n",
    "                bic = result.bic\n",
    "                log_likelihood = result.loglikelihood\n",
    "                \n",
    "                print(f\"  {model_name}:\")\n",
    "                print(f\"    å¯¾æ•°å°¤åº¦: {log_likelihood:.4f}\")\n",
    "                print(f\"    AIC: {aic:.4f}\")\n",
    "                print(f\"    BIC: {bic:.4f}\")\n",
    "                \n",
    "                # æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "                conditional_volatility = result.conditional_volatility\n",
    "                \n",
    "                model_results[model_name] = {\n",
    "                    'model': result,\n",
    "                    'aic': aic,\n",
    "                    'bic': bic,\n",
    "                    'log_likelihood': log_likelihood,\n",
    "                    'conditional_volatility': conditional_volatility,\n",
    "                    'residuals': result.resid,\n",
    "                    'standardized_residuals': result.std_resid\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  {model_name}: æ¨å®šã‚¨ãƒ©ãƒ¼ - {e}\")\n",
    "                continue\n",
    "        \n",
    "        # æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆAICåŸºæº–ï¼‰\n",
    "        if model_results:\n",
    "            best_model_name = min(model_results.keys(), key=lambda x: model_results[x]['aic'])\n",
    "            print(f\"  \\n  ğŸ“Š æœ€é©ãƒ¢ãƒ‡ãƒ«ï¼ˆAICåŸºæº–ï¼‰: {best_model_name}\")\n",
    "            \n",
    "            garch_models[name] = {\n",
    "                'all_models': model_results,\n",
    "                'best_model_name': best_model_name,\n",
    "                'best_model': model_results[best_model_name]\n",
    "            }\n",
    "    \n",
    "    return garch_models\n",
    "\n",
    "# GARCHãƒ¢ãƒ‡ãƒ«æ¨å®š\n",
    "garch_models = estimate_garch_models(spreads_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_garch_results(garch_models, spreads_data):\n",
    "    \"\"\"GARCHãƒ¢ãƒ‡ãƒ«çµæœã®å¯è¦–åŒ–\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'M1-M2: ãƒªã‚¿ãƒ¼ãƒ³ã¨æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "            'M1-M2: æ¨™æº–åŒ–æ®‹å·®',\n",
    "            'M2-M3: ãƒªã‚¿ãƒ¼ãƒ³ã¨æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "            'M2-M3: æ¨™æº–åŒ–æ®‹å·®',\n",
    "            'M3-M4: ãƒªã‚¿ãƒ¼ãƒ³ã¨æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "            'M3-M4: æ¨™æº–åŒ–æ®‹å·®'\n",
    "        ),\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    for i, (col, name, color) in enumerate(zip(return_columns, spread_names, colors)):\n",
    "        if name in garch_models:\n",
    "            best_model = garch_models[name]['best_model']\n",
    "            \n",
    "            returns = spreads_data[col].dropna() * 100\n",
    "            cond_vol = best_model['conditional_volatility']\n",
    "            std_resid = best_model['standardized_residuals']\n",
    "            \n",
    "            # ãƒªã‚¿ãƒ¼ãƒ³ã¨æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=returns.index,\n",
    "                    y=returns,\n",
    "                    name=f'{name} ãƒªã‚¿ãƒ¼ãƒ³',\n",
    "                    line=dict(color=color, width=0.8),\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                row=i+1, col=1\n",
    "            )\n",
    "            \n",
    "            # æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®Â±2Ïƒãƒãƒ³ãƒ‰\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cond_vol.index,\n",
    "                    y=2 * cond_vol,\n",
    "                    name=f'{name} +2Ïƒ',\n",
    "                    line=dict(color='red', dash='dash', width=1),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=i+1, col=1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cond_vol.index,\n",
    "                    y=-2 * cond_vol,\n",
    "                    name=f'{name} -2Ïƒ',\n",
    "                    line=dict(color='red', dash='dash', width=1),\n",
    "                    fill='tonexty',\n",
    "                    fillcolor='rgba(255,0,0,0.1)',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=i+1, col=1\n",
    "            )\n",
    "            \n",
    "            # æ¨™æº–åŒ–æ®‹å·®\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=std_resid.index,\n",
    "                    y=std_resid,\n",
    "                    name=f'{name} æ¨™æº–åŒ–æ®‹å·®',\n",
    "                    line=dict(color='purple', width=0.8),\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=2)\n",
    "                ),\n",
    "                row=i+1, col=2\n",
    "            )\n",
    "            \n",
    "            # Â±2Ïƒãƒ©ã‚¤ãƒ³\n",
    "            fig.add_hline(y=2, line_dash=\"dash\", line_color=\"red\", \n",
    "                         line_width=1, row=i+1, col=2)\n",
    "            fig.add_hline(y=-2, line_dash=\"dash\", line_color=\"red\", \n",
    "                         line_width=1, row=i+1, col=2)\n",
    "            fig.add_hline(y=0, line_dash=\"dot\", line_color=\"black\", \n",
    "                         line_width=1, row=i+1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"GARCH ãƒ¢ãƒ‡ãƒ«æ¨å®šçµæœ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=1000,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    for i in range(3):\n",
    "        fig.update_yaxes(title_text=\"ãƒªã‚¿ãƒ¼ãƒ³ (%)\", row=i+1, col=1)\n",
    "        fig.update_yaxes(title_text=\"æ¨™æº–åŒ–æ®‹å·®\", row=i+1, col=2)\n",
    "        if i == 2:\n",
    "            fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=i+1, col=1)\n",
    "            fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=i+1, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# GARCHãƒ¢ãƒ‡ãƒ«çµæœã®å¯è¦–åŒ–\n",
    "garch_chart = plot_garch_results(garch_models, spreads_data)\n",
    "garch_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "garch_chart.write_image('../generated_images/adjacent_spreads_garch_models.png', \n",
    "                       width=1200, height=1000, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ãƒªã‚¹ã‚¯æŒ‡æ¨™ã®è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_metrics(garch_models, spreads_data):\n",
    "    \"\"\"VaRã€Expected Shortfallç­‰ã®ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    confidence_levels = [0.95, 0.99, 0.995]\n",
    "    \n",
    "    print(\"âš ï¸ ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—çµæœ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    risk_metrics = {}\n",
    "    \n",
    "    for col, name in zip(return_columns, spread_names):\n",
    "        if name not in garch_models:\n",
    "            continue\n",
    "            \n",
    "        returns = spreads_data[col].dropna() * 100\n",
    "        best_model = garch_models[name]['best_model']\n",
    "        cond_vol = best_model['conditional_volatility']\n",
    "        std_resid = best_model['standardized_residuals']\n",
    "        \n",
    "        print(f\"\\n{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        \n",
    "        current_volatility = cond_vol.iloc[-1]  # æœ€æ–°ã®æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "        print(f\"  æœ€æ–°æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {current_volatility:.4f}%\")\n",
    "        \n",
    "        spread_risk_metrics = {\n",
    "            'current_volatility': current_volatility,\n",
    "            'conditional_volatility': cond_vol,\n",
    "            'var': {},\n",
    "            'expected_shortfall': {},\n",
    "            'parametric_var': {},\n",
    "            'historical_var': {}\n",
    "        }\n",
    "        \n",
    "        # å„ä¿¡é ¼æ°´æº–ã§ãƒªã‚¹ã‚¯æŒ‡æ¨™ã‚’è¨ˆç®—\n",
    "        for alpha in confidence_levels:\n",
    "            print(f\"\\n  ä¿¡é ¼æ°´æº– {alpha*100:.1f}%:\")\n",
    "            \n",
    "            # 1. ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«VaR\n",
    "            historical_var = np.percentile(returns, (1-alpha)*100)\n",
    "            \n",
    "            # 2. ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯VaRï¼ˆæ­£è¦åˆ†å¸ƒä»®å®šï¼‰\n",
    "            parametric_var = norm.ppf(1-alpha) * current_volatility\n",
    "            \n",
    "            # 3. GARCH-VaRï¼ˆtåˆ†å¸ƒä»®å®šï¼‰\n",
    "            # æ¨™æº–åŒ–æ®‹å·®ã®åˆ†å¸ƒã‚’tåˆ†å¸ƒã§ãƒ•ã‚£ãƒƒãƒˆ\n",
    "            try:\n",
    "                clean_std_resid = std_resid.dropna()\n",
    "                df_fitted, loc_fitted, scale_fitted = stats.t.fit(clean_std_resid)\n",
    "                garch_var = t.ppf(1-alpha, df=df_fitted, loc=loc_fitted, scale=scale_fitted) * current_volatility\n",
    "            except:\n",
    "                garch_var = parametric_var  # ãƒ•ã‚£ãƒƒãƒˆã«å¤±æ•—ã—ãŸå ´åˆã¯æ­£è¦åˆ†å¸ƒã‚’ä½¿ç”¨\n",
    "            \n",
    "            # 4. Expected Shortfall (CVaR)\n",
    "            var_threshold = historical_var\n",
    "            tail_returns = returns[returns <= var_threshold]\n",
    "            if len(tail_returns) > 0:\n",
    "                expected_shortfall = tail_returns.mean()\n",
    "            else:\n",
    "                expected_shortfall = historical_var\n",
    "            \n",
    "            print(f\"    ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«VaR: {historical_var:.4f}%\")\n",
    "            print(f\"    ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯VaR: {parametric_var:.4f}%\")\n",
    "            print(f\"    GARCH-VaR: {garch_var:.4f}%\")\n",
    "            print(f\"    Expected Shortfall: {expected_shortfall:.4f}%\")\n",
    "            \n",
    "            # çµæœã‚’ä¿å­˜\n",
    "            alpha_key = f'{alpha*100:.1f}%'\n",
    "            spread_risk_metrics['historical_var'][alpha_key] = historical_var\n",
    "            spread_risk_metrics['parametric_var'][alpha_key] = parametric_var\n",
    "            spread_risk_metrics['var'][alpha_key] = garch_var\n",
    "            spread_risk_metrics['expected_shortfall'][alpha_key] = expected_shortfall\n",
    "        \n",
    "        # è¿½åŠ ã®ãƒªã‚¹ã‚¯æŒ‡æ¨™\n",
    "        max_drawdown = calculate_max_drawdown(returns)\n",
    "        avg_vol_30d = cond_vol.rolling(window=30).mean().iloc[-1]\n",
    "        vol_of_vol = cond_vol.rolling(window=30).std().iloc[-1]\n",
    "        \n",
    "        print(f\"\\n  è¿½åŠ ãƒªã‚¹ã‚¯æŒ‡æ¨™:\")\n",
    "        print(f\"    æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {max_drawdown:.4f}%\")\n",
    "        print(f\"    30æ—¥å¹³å‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {avg_vol_30d:.4f}%\")\n",
    "        print(f\"    ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {vol_of_vol:.4f}%\")\n",
    "        \n",
    "        spread_risk_metrics.update({\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'avg_volatility_30d': avg_vol_30d,\n",
    "            'volatility_of_volatility': vol_of_vol\n",
    "        })\n",
    "        \n",
    "        risk_metrics[name] = spread_risk_metrics\n",
    "    \n",
    "    return risk_metrics\n",
    "\n",
    "def calculate_max_drawdown(returns):\n",
    "    \"\"\"æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®è¨ˆç®—\"\"\"\n",
    "    cumulative = (1 + returns/100).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - rolling_max) / rolling_max * 100\n",
    "    return drawdown.min()\n",
    "\n",
    "# ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—\n",
    "risk_metrics = calculate_risk_metrics(garch_models, spreads_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_metrics(risk_metrics, spreads_data):\n",
    "    \"\"\"ãƒªã‚¹ã‚¯æŒ‡æ¨™ã®å¯è¦–åŒ–\"\"\"\n",
    "    return_columns = ['M1_M2_return', 'M2_M3_return', 'M3_M4_return']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'VaRæ¯”è¼ƒï¼ˆ95%ä¿¡é ¼æ°´æº–ï¼‰',\n",
    "            'æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®æ¨ç§»',\n",
    "            'VaRãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«VaR vs å®Ÿç¸¾ï¼‰',\n",
    "            'ãƒªã‚¹ã‚¯æŒ‡æ¨™ã‚µãƒãƒªãƒ¼'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    # 1. VaRæ¯”è¼ƒ\n",
    "    var_types = ['ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«VaR', 'ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯VaR', 'GARCH-VaR']\n",
    "    var_keys = ['historical_var', 'parametric_var', 'var']\n",
    "    \n",
    "    x_pos = np.arange(len(spread_names))\n",
    "    bar_width = 0.25\n",
    "    \n",
    "    for i, (var_type, var_key) in enumerate(zip(var_types, var_keys)):\n",
    "        var_values = []\n",
    "        for name in spread_names:\n",
    "            if name in risk_metrics:\n",
    "                var_values.append(abs(risk_metrics[name][var_key]['95.0%']))\n",
    "            else:\n",
    "                var_values.append(0)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[f\"{name}<br>({var_type})\" for name in spread_names],\n",
    "                y=var_values,\n",
    "                name=var_type,\n",
    "                marker_color=colors[i],\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®æ¨ç§»\n",
    "    for i, (name, color) in enumerate(zip(spread_names, colors)):\n",
    "        if name in risk_metrics:\n",
    "            cond_vol = risk_metrics[name]['conditional_volatility']\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cond_vol.index,\n",
    "                    y=cond_vol,\n",
    "                    name=f'{name} æ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "                    line=dict(color=color, width=1.5)\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "    \n",
    "    # 3. VaRãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆM1-M2ã®ã¿ï¼‰\n",
    "    if 'M1-M2' in risk_metrics:\n",
    "        returns = spreads_data['M1_M2_return'].dropna() * 100\n",
    "        historical_var_95 = risk_metrics['M1-M2']['historical_var']['95.0%']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=returns.index,\n",
    "                y=returns,\n",
    "                name='M1-M2 ãƒªã‚¿ãƒ¼ãƒ³',\n",
    "                line=dict(color='blue', width=0.8),\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # VaRãƒ©ã‚¤ãƒ³\n",
    "        fig.add_hline(y=historical_var_95, line_dash=\"dash\", line_color=\"red\", \n",
    "                     line_width=2, row=2, col=1)\n",
    "        \n",
    "        # VaRé•åã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ\n",
    "        var_violations = returns[returns < historical_var_95]\n",
    "        if len(var_violations) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=var_violations.index,\n",
    "                    y=var_violations,\n",
    "                    mode='markers',\n",
    "                    name='VaRé•å',\n",
    "                    marker=dict(color='red', size=6, symbol='x')\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # VaRé•åç‡\n",
    "        violation_rate = len(var_violations) / len(returns) * 100\n",
    "        expected_rate = 5.0  # 95%VaRã®æœŸå¾…é•åç‡\n",
    "        \n",
    "    # 4. ãƒªã‚¹ã‚¯æŒ‡æ¨™ã‚µãƒãƒªãƒ¼ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰\n",
    "    summary_data = []\n",
    "    for name in spread_names:\n",
    "        if name in risk_metrics:\n",
    "            metrics = risk_metrics[name]\n",
    "            summary_data.append([\n",
    "                name,\n",
    "                f\"{metrics['current_volatility']:.3f}%\",\n",
    "                f\"{abs(metrics['var']['95.0%']):.3f}%\",\n",
    "                f\"{abs(metrics['expected_shortfall']['95.0%']):.3f}%\",\n",
    "                f\"{metrics['max_drawdown']:.3f}%\"\n",
    "            ])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(\n",
    "                values=['ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰', 'ç¾åœ¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£', '95% VaR', '95% ES', 'æœ€å¤§DD'],\n",
    "                fill_color='lightblue',\n",
    "                font=dict(size=12)\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=list(zip(*summary_data)) if summary_data else [[], [], [], [], []],\n",
    "                fill_color='white',\n",
    "                font=dict(size=11)\n",
    "            )\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"ãƒªã‚¹ã‚¯æŒ‡æ¨™åˆ†æ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    fig.update_yaxes(title_text=\"VaR (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=1, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"ãƒªã‚¿ãƒ¼ãƒ³ (%)\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ãƒªã‚¹ã‚¯æŒ‡æ¨™ã®å¯è¦–åŒ–\n",
    "risk_chart = plot_risk_metrics(risk_metrics, spreads_data)\n",
    "risk_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "risk_chart.write_image('../generated_images/adjacent_spreads_risk_metrics.png', \n",
    "                      width=1200, height=800, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_volatility_regimes(risk_metrics, spreads_data):\n",
    "    \"\"\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æ\"\"\"\n",
    "    print(\"ğŸ­ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    regime_analysis = {}\n",
    "    \n",
    "    for name in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if name not in risk_metrics:\n",
    "            continue\n",
    "            \n",
    "        cond_vol = risk_metrics[name]['conditional_volatility']\n",
    "        \n",
    "        print(f\"\\n{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        \n",
    "        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®åˆ†ä½æ•°ã§ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡\n",
    "        vol_25 = cond_vol.quantile(0.25)\n",
    "        vol_50 = cond_vol.quantile(0.50)\n",
    "        vol_75 = cond_vol.quantile(0.75)\n",
    "        vol_95 = cond_vol.quantile(0.95)\n",
    "        \n",
    "        print(f\"  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†ä½æ•°:\")\n",
    "        print(f\"    25%åˆ†ä½: {vol_25:.4f}%\")\n",
    "        print(f\"    50%åˆ†ä½: {vol_50:.4f}%\")\n",
    "        print(f\"    75%åˆ†ä½: {vol_75:.4f}%\")\n",
    "        print(f\"    95%åˆ†ä½: {vol_95:.4f}%\")\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡\n",
    "        regimes = pd.Series(index=cond_vol.index, dtype='object')\n",
    "        regimes[cond_vol <= vol_25] = 'Low'\n",
    "        regimes[(cond_vol > vol_25) & (cond_vol <= vol_50)] = 'Medium-Low'\n",
    "        regimes[(cond_vol > vol_50) & (cond_vol <= vol_75)] = 'Medium-High'\n",
    "        regimes[cond_vol > vol_75] = 'High'\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ çµ±è¨ˆ\n",
    "        regime_stats = regimes.value_counts(normalize=True) * 100\n",
    "        \n",
    "        print(f\"\\n  ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†å¸ƒ:\")\n",
    "        for regime, percentage in regime_stats.items():\n",
    "            print(f\"    {regime}: {percentage:.1f}%\")\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›ã®åˆ†æ\n",
    "        regime_changes = (regimes != regimes.shift(1)).sum()\n",
    "        avg_regime_duration = len(regimes) / regime_changes if regime_changes > 0 else len(regimes)\n",
    "        \n",
    "        print(f\"\\n  ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›:\")\n",
    "        print(f\"    è»¢æ›å›æ•°: {regime_changes}\")\n",
    "        print(f\"    å¹³å‡ç¶™ç¶šæœŸé–“: {avg_regime_duration:.1f}æ—¥\")\n",
    "        \n",
    "        # å„ãƒ¬ã‚¸ãƒ¼ãƒ ã§ã®ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆ\n",
    "        return_col = f\"{name.replace('-', '_')}_return\"\n",
    "        if return_col in spreads_data.columns:\n",
    "            returns = spreads_data[return_col] * 100\n",
    "            \n",
    "            print(f\"\\n  ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆ:\")\n",
    "            for regime in ['Low', 'Medium-Low', 'Medium-High', 'High']:\n",
    "                regime_returns = returns[regimes == regime]\n",
    "                if len(regime_returns) > 0:\n",
    "                    print(f\"    {regime}:\")\n",
    "                    print(f\"      å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {regime_returns.mean():.4f}%\")\n",
    "                    print(f\"      ãƒªã‚¿ãƒ¼ãƒ³æ¨™æº–åå·®: {regime_returns.std():.4f}%\")\n",
    "                    print(f\"      æœ€å¤§æå¤±: {regime_returns.min():.4f}%\")\n",
    "        \n",
    "        regime_analysis[name] = {\n",
    "            'conditional_volatility': cond_vol,\n",
    "            'regimes': regimes,\n",
    "            'quantiles': {\n",
    "                '25%': vol_25,\n",
    "                '50%': vol_50,\n",
    "                '75%': vol_75,\n",
    "                '95%': vol_95\n",
    "            },\n",
    "            'regime_distribution': regime_stats,\n",
    "            'regime_changes': regime_changes,\n",
    "            'avg_duration': avg_regime_duration\n",
    "        }\n",
    "    \n",
    "    return regime_analysis\n",
    "\n",
    "# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æå®Ÿè¡Œ\n",
    "regime_analysis = analyze_volatility_regimes(risk_metrics, spreads_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volatility_regimes(regime_analysis):\n",
    "    \"\"\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ã®å¯è¦–åŒ–\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'M1-M2: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ',\n",
    "            'ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†å¸ƒ',\n",
    "            'M2-M3: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ',\n",
    "            'ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›é »åº¦'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    regime_colors = {\n",
    "        'Low': 'green',\n",
    "        'Medium-Low': 'yellow',\n",
    "        'Medium-High': 'orange', \n",
    "        'High': 'red'\n",
    "    }\n",
    "    \n",
    "    # 1. M1-M2ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ \n",
    "    if 'M1-M2' in regime_analysis:\n",
    "        m1m2_data = regime_analysis['M1-M2']\n",
    "        cond_vol = m1m2_data['conditional_volatility']\n",
    "        regimes = m1m2_data['regimes']\n",
    "        \n",
    "        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ©ã‚¤ãƒ³\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cond_vol.index,\n",
    "                y=cond_vol,\n",
    "                name='M1-M2 ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "                line=dict(color='blue', width=1),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ å¢ƒç•Œç·š\n",
    "        quantiles = m1m2_data['quantiles']\n",
    "        for label, value in quantiles.items():\n",
    "            fig.add_hline(y=value, line_dash=\"dash\", line_color=\"gray\", \n",
    "                         line_width=1, row=1, col=1)\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "        for regime, color in regime_colors.items():\n",
    "            regime_mask = regimes == regime\n",
    "            if regime_mask.any():\n",
    "                regime_vol = cond_vol[regime_mask]\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=regime_vol.index,\n",
    "                        y=regime_vol,\n",
    "                        mode='markers',\n",
    "                        name=f'{regime} ãƒ¬ã‚¸ãƒ¼ãƒ ',\n",
    "                        marker=dict(color=color, size=3, opacity=0.7)\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "    \n",
    "    # 2. ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†å¸ƒ\n",
    "    all_regime_dist = []\n",
    "    spread_labels = []\n",
    "    \n",
    "    for name in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if name in regime_analysis:\n",
    "            regime_dist = regime_analysis[name]['regime_distribution']\n",
    "            for regime in ['Low', 'Medium-Low', 'Medium-High', 'High']:\n",
    "                if regime in regime_dist:\n",
    "                    all_regime_dist.append(regime_dist[regime])\n",
    "                    spread_labels.append(f'{name}<br>{regime}')\n",
    "                else:\n",
    "                    all_regime_dist.append(0)\n",
    "                    spread_labels.append(f'{name}<br>{regime}')\n",
    "    \n",
    "    # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†å¸ƒã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ\n",
    "    x_pos = 0\n",
    "    for name in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if name in regime_analysis:\n",
    "            regime_dist = regime_analysis[name]['regime_distribution']\n",
    "            for regime in ['Low', 'Medium-Low', 'Medium-High', 'High']:\n",
    "                value = regime_dist.get(regime, 0)\n",
    "                fig.add_trace(\n",
    "                    go.Bar(\n",
    "                        x=[f'{name}<br>{regime}'],\n",
    "                        y=[value],\n",
    "                        name=regime,\n",
    "                        marker_color=regime_colors[regime],\n",
    "                        showlegend=(name == 'M1-M2')  # æœ€åˆã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ã®ã¿å‡¡ä¾‹è¡¨ç¤º\n",
    "                    ),\n",
    "                    row=1, col=2\n",
    "                )\n",
    "    \n",
    "    # 3. M2-M3ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ \n",
    "    if 'M2-M3' in regime_analysis:\n",
    "        m2m3_data = regime_analysis['M2-M3']\n",
    "        cond_vol = m2m3_data['conditional_volatility']\n",
    "        regimes = m2m3_data['regimes']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cond_vol.index,\n",
    "                y=cond_vol,\n",
    "                name='M2-M3 ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',\n",
    "                line=dict(color='red', width=1),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # ãƒ¬ã‚¸ãƒ¼ãƒ å¢ƒç•Œç·š\n",
    "        quantiles = m2m3_data['quantiles']\n",
    "        for label, value in quantiles.items():\n",
    "            fig.add_hline(y=value, line_dash=\"dash\", line_color=\"gray\", \n",
    "                         line_width=1, row=2, col=1)\n",
    "    \n",
    "    # 4. ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›é »åº¦\n",
    "    regime_changes = []\n",
    "    avg_durations = []\n",
    "    spread_names = []\n",
    "    \n",
    "    for name in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if name in regime_analysis:\n",
    "            regime_changes.append(regime_analysis[name]['regime_changes'])\n",
    "            avg_durations.append(regime_analysis[name]['avg_duration'])\n",
    "            spread_names.append(name)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=spread_names,\n",
    "            y=regime_changes,\n",
    "            name='ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›å›æ•°',\n",
    "            marker_color='lightblue',\n",
    "            yaxis='y',\n",
    "            offsetgroup=1\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=spread_names,\n",
    "            y=avg_durations,\n",
    "            name='å¹³å‡ç¶™ç¶šæœŸé–“ï¼ˆæ—¥ï¼‰',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='red', width=2),\n",
    "            marker=dict(size=8),\n",
    "            yaxis='y2'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    fig.update_yaxes(title_text=\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"æ¯”ç‡ (%)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"è»¢æ›å›æ•°\", row=2, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=2, col=1)\n",
    "    \n",
    "    # ç¬¬2è»¸ã®è¨­å®š\n",
    "    fig.update_layout(\n",
    "        yaxis4=dict(\n",
    "            title=\"å¹³å‡ç¶™ç¶šæœŸé–“ï¼ˆæ—¥ï¼‰\",\n",
    "            overlaying=\"y3\",\n",
    "            side=\"right\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ã®å¯è¦–åŒ–\n",
    "regime_chart = plot_volatility_regimes(regime_analysis)\n",
    "regime_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "regime_chart.write_image('../generated_images/adjacent_spreads_volatility_regimes.png', \n",
    "                        width=1200, height=800, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åˆ†æçµæœã‚µãƒãƒªãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°åˆ†æã‚µãƒãƒªãƒ¼\n",
    "def generate_volatility_modeling_summary(vol_stats, arch_results, garch_models, \n",
    "                                        risk_metrics, regime_analysis):\n",
    "    \"\"\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°åˆ†æã®åŒ…æ‹¬çš„ã‚µãƒãƒªãƒ¼\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°åˆ†æã‚µãƒãƒªãƒ¼\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹æ€§:\")\n",
    "    for spread in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if spread in vol_stats.columns:\n",
    "            daily_vol = vol_stats.loc['æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£(%)', spread]\n",
    "            annual_vol = vol_stats.loc['å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£(%)', spread]\n",
    "            skewness = vol_stats.loc['æ­ªåº¦', spread]\n",
    "            kurtosis = vol_stats.loc['å°–åº¦', spread]\n",
    "            \n",
    "            print(f\"  {spread}:\")\n",
    "            print(f\"    æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {daily_vol:.3f}%\")\n",
    "            print(f\"    å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {annual_vol:.1f}%\")\n",
    "            print(f\"    æ­ªåº¦: {skewness:.3f} ({'å³æ­ªã¿' if skewness > 0 else 'å·¦æ­ªã¿' if skewness < 0 else 'å¯¾ç§°'})\")\n",
    "            print(f\"    å°–åº¦: {kurtosis:.3f} ({'å°–é‹­' if kurtosis > 0 else 'å¹³å¦'})\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¬ ARCHåŠ¹æœæ¤œå®š:\")\n",
    "    arch_detected = 0\n",
    "    vol_clustering_detected = 0\n",
    "    \n",
    "    for spread in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if spread in arch_results:\n",
    "            has_arch = arch_results[spread]['has_arch_effects']\n",
    "            has_clustering = arch_results[spread]['has_volatility_clustering']\n",
    "            \n",
    "            print(f\"  {spread}:\")\n",
    "            print(f\"    ARCHåŠ¹æœ: {'ã‚ã‚Š' if has_arch else 'ãªã—'}\")\n",
    "            print(f\"    ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°: {'ã‚ã‚Š' if has_clustering else 'ãªã—'}\")\n",
    "            \n",
    "            if has_arch:\n",
    "                arch_detected += 1\n",
    "            if has_clustering:\n",
    "                vol_clustering_detected += 1\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ GARCHãƒ¢ãƒ‡ãƒ«é¸æŠ:\")\n",
    "    best_models = {}\n",
    "    for spread in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if spread in garch_models:\n",
    "            best_model_name = garch_models[spread]['best_model_name']\n",
    "            best_aic = garch_models[spread]['best_model']['aic']\n",
    "            \n",
    "            print(f\"  {spread}: {best_model_name} (AIC: {best_aic:.2f})\")\n",
    "            best_models[spread] = best_model_name\n",
    "    \n",
    "    print(f\"\\nâš ï¸ ãƒªã‚¹ã‚¯æŒ‡æ¨™ï¼ˆ95%ä¿¡é ¼æ°´æº–ï¼‰:\")\n",
    "    for spread in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if spread in risk_metrics:\n",
    "            current_vol = risk_metrics[spread]['current_volatility']\n",
    "            var_95 = abs(risk_metrics[spread]['var']['95.0%'])\n",
    "            es_95 = abs(risk_metrics[spread]['expected_shortfall']['95.0%'])\n",
    "            max_dd = risk_metrics[spread]['max_drawdown']\n",
    "            \n",
    "            print(f\"  {spread}:\")\n",
    "            print(f\"    ç¾åœ¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {current_vol:.3f}%\")\n",
    "            print(f\"    95% VaR: {var_95:.3f}%\")\n",
    "            print(f\"    95% ES: {es_95:.3f}%\")\n",
    "            print(f\"    æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {max_dd:.3f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ­ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ :\")\n",
    "    for spread in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        if spread in regime_analysis:\n",
    "            regime_changes = regime_analysis[spread]['regime_changes']\n",
    "            avg_duration = regime_analysis[spread]['avg_duration']\n",
    "            high_vol_ratio = regime_analysis[spread]['regime_distribution'].get('High', 0)\n",
    "            \n",
    "            print(f\"  {spread}:\")\n",
    "            print(f\"    ãƒ¬ã‚¸ãƒ¼ãƒ è»¢æ›: {regime_changes}å›\")\n",
    "            print(f\"    å¹³å‡ç¶™ç¶šæœŸé–“: {avg_duration:.1f}æ—¥\")\n",
    "            print(f\"    é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“: {high_vol_ratio:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ æŠ•è³‡ãƒ»ãƒªã‚¹ã‚¯ç®¡ç†ã¸ã®ç¤ºå”†:\")\n",
    "    \n",
    "    # ARCHåŠ¹æœã«åŸºã¥ãç¤ºå”†\n",
    "    if arch_detected >= 2:\n",
    "        print(f\"  â€¢ {arch_detected}/3ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã§ARCHåŠ¹æœæ¤œå‡º â†’ GARCHãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ãŒæœ‰åŠ¹\")\n",
    "    \n",
    "    if vol_clustering_detected >= 2:\n",
    "        print(f\"  â€¢ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ç¢ºèª â†’ é«˜ãƒœãƒ©æœŸé–“ã§ã®æ…é‡ãªãƒã‚¸ã‚·ãƒ§ãƒ³ç®¡ç†å¿…è¦\")\n",
    "    \n",
    "    # æœ€ã‚‚ãƒªã‚¹ã‚­ãƒ¼ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚’ç‰¹å®š\n",
    "    if risk_metrics:\n",
    "        highest_var_spread = max(risk_metrics.keys(), \n",
    "                               key=lambda x: abs(risk_metrics[x]['var']['95.0%']))\n",
    "        highest_var = abs(risk_metrics[highest_var_spread]['var']['95.0%'])\n",
    "        print(f\"  â€¢ æœ€é«˜ãƒªã‚¹ã‚¯ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰: {highest_var_spread} (95% VaR: {highest_var:.3f}%)\")\n",
    "    \n",
    "    # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æã«åŸºã¥ãç¤ºå”†\n",
    "    if regime_analysis:\n",
    "        unstable_spreads = []\n",
    "        for spread, data in regime_analysis.items():\n",
    "            if data['regime_changes'] > len(data['conditional_volatility']) / 50:  # é »ç¹ãªè»¢æ›\n",
    "                unstable_spreads.append(spread)\n",
    "        \n",
    "        if unstable_spreads:\n",
    "            print(f\"  â€¢ ãƒ¬ã‚¸ãƒ¼ãƒ ä¸å®‰å®š: {', '.join(unstable_spreads)} â†’ å‹•çš„ãƒ˜ãƒƒã‚¸æˆ¦ç•¥æ¨å¥¨\")\n",
    "    \n",
    "    print(f\"\\nğŸ›¡ï¸ ãƒªã‚¹ã‚¯ç®¡ç†æ¨å¥¨äº‹é …:\")\n",
    "    print(f\"  â€¢ GARCHãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®å‹•çš„VaRç®¡ç†\")\n",
    "    print(f\"  â€¢ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ å¿œç­”å‹ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚¸ãƒ³ã‚°\")\n",
    "    print(f\"  â€¢ é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“ã§ã®æåˆ‡ã‚ŠåŸºæº–å³æ ¼åŒ–\")\n",
    "    print(f\"  â€¢ Expected Shortfallã«ã‚ˆã‚‹æ¥µç«¯ãƒªã‚¹ã‚¯ã‚·ãƒŠãƒªã‚ªç®¡ç†\")\n",
    "    \n",
    "    return {\n",
    "        'arch_effects_detected': arch_detected,\n",
    "        'volatility_clustering_detected': vol_clustering_detected,\n",
    "        'best_models': best_models,\n",
    "        'highest_risk_spread': highest_var_spread if risk_metrics else None,\n",
    "        'regime_instability': unstable_spreads if regime_analysis else []\n",
    "    }\n",
    "\n",
    "# ã‚µãƒãƒªãƒ¼ç”Ÿæˆ\n",
    "volatility_summary = generate_volatility_modeling_summary(\n",
    "    vol_stats, arch_results, garch_models, risk_metrics, regime_analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æçµæœã®ä¿å­˜\n",
    "def save_volatility_analysis_results(vol_stats, garch_models, risk_metrics, \n",
    "                                    regime_analysis, volatility_summary):\n",
    "    \"\"\"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\"\"\"\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "    os.makedirs('../analysis_results/adjacent_spreads', exist_ok=True)\n",
    "    \n",
    "    # 1. åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±è¨ˆ\n",
    "    vol_stats.to_csv('../analysis_results/adjacent_spreads/volatility_statistics.csv', \n",
    "                     encoding='utf-8-sig')\n",
    "    \n",
    "    # 2. GARCHæ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "    garch_volatilities = pd.DataFrame()\n",
    "    for spread, models in garch_models.items():\n",
    "        best_model = models['best_model']\n",
    "        garch_volatilities[f'{spread}_volatility'] = best_model['conditional_volatility']\n",
    "    \n",
    "    if not garch_volatilities.empty:\n",
    "        garch_volatilities.to_csv('../analysis_results/adjacent_spreads/garch_conditional_volatility.csv', \n",
    "                                 encoding='utf-8-sig')\n",
    "    \n",
    "    # 3. VaRã¨ãƒªã‚¹ã‚¯æŒ‡æ¨™\n",
    "    risk_summary = pd.DataFrame()\n",
    "    for spread, metrics in risk_metrics.items():\n",
    "        risk_summary[f'{spread}_current_vol'] = [metrics['current_volatility']]\n",
    "        risk_summary[f'{spread}_95_var'] = [abs(metrics['var']['95.0%'])]\n",
    "        risk_summary[f'{spread}_95_es'] = [abs(metrics['expected_shortfall']['95.0%'])]\n",
    "        risk_summary[f'{spread}_max_drawdown'] = [metrics['max_drawdown']]\n",
    "    \n",
    "    if not risk_summary.empty:\n",
    "        risk_summary.to_csv('../analysis_results/adjacent_spreads/risk_metrics_summary.csv', \n",
    "                           encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # 4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ \n",
    "    regime_data = pd.DataFrame()\n",
    "    for spread, analysis in regime_analysis.items():\n",
    "        regime_data[f'{spread}_regime'] = analysis['regimes']\n",
    "        regime_data[f'{spread}_volatility'] = analysis['conditional_volatility']\n",
    "    \n",
    "    if not regime_data.empty:\n",
    "        regime_data.to_csv('../analysis_results/adjacent_spreads/volatility_regimes.csv', \n",
    "                          encoding='utf-8-sig')\n",
    "    \n",
    "    # 5. åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆJSONï¼‰\n",
    "    import json\n",
    "    \n",
    "    with open('../analysis_results/adjacent_spreads/volatility_modeling_summary.json', \n",
    "              'w', encoding='utf-8') as f:\n",
    "        json.dump(volatility_summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ:\")\n",
    "    print(f\"  ğŸ“Š åŸºæœ¬çµ±è¨ˆ: ../analysis_results/adjacent_spreads/volatility_statistics.csv\")\n",
    "    print(f\"  ğŸ“ˆ GARCHæ¡ä»¶ä»˜ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: ../analysis_results/adjacent_spreads/garch_conditional_volatility.csv\")\n",
    "    print(f\"  âš ï¸ ãƒªã‚¹ã‚¯æŒ‡æ¨™: ../analysis_results/adjacent_spreads/risk_metrics_summary.csv\")\n",
    "    print(f\"  ğŸ­ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ : ../analysis_results/adjacent_spreads/volatility_regimes.csv\")\n",
    "    print(f\"  ğŸ“ åˆ†æã‚µãƒãƒªãƒ¼: ../analysis_results/adjacent_spreads/volatility_modeling_summary.json\")\n",
    "\n",
    "# åˆ†æçµæœä¿å­˜\n",
    "save_volatility_analysis_results(\n",
    "    vol_stats, garch_models, risk_metrics, regime_analysis, volatility_summary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "ã“ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒªãƒ³ã‚°åˆ†æã«ã‚ˆã‚Šã€éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ãƒªã‚¹ã‚¯ç‰¹æ€§ã‚’è©³ç´°ã«æŠŠæ¡ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "### ä¸»è¦ç™ºè¦‹äº‹é …\n",
    "1. **ARCHåŠ¹æœ**: è¤‡æ•°ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã§æ¡ä»¶ä»˜ãåˆ†æ•£ä¸å‡ä¸€æ€§ã‚’ç¢ºèª\n",
    "2. **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: é«˜ãƒœãƒ©æœŸé–“ã¨ä½ãƒœãƒ©æœŸé–“ã®æ˜ç¢ºãªåŒºåˆ¥\n",
    "3. **GARCHãƒ¢ãƒ‡ãƒ«**: å„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã«æœ€é©ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®š\n",
    "4. **ãƒªã‚¹ã‚¯æŒ‡æ¨™**: VaR/ESã«ã‚ˆã‚‹å®šé‡çš„ãƒªã‚¹ã‚¯è©•ä¾¡\n",
    "5. **ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æ**: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç’°å¢ƒã®å‘¨æœŸçš„å¤‰åŒ–\n",
    "\n",
    "### æ¬¡ã®åˆ†æã‚¹ãƒ†ãƒƒãƒ—\n",
    "1. **æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬**: ã‚ˆã‚Šé«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«\n",
    "2. **å–å¼•æˆ¦ç•¥æ§‹ç¯‰**: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ã®å–å¼•æˆ¦ç•¥\n",
    "3. **å‹•çš„ãƒ˜ãƒƒã‚¸**: ãƒ¬ã‚¸ãƒ¼ãƒ å¿œç­”å‹ãƒªã‚¹ã‚¯ç®¡ç†\n",
    "4. **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**: å®Ÿéš›ã®å–å¼•æˆ¦ç•¥ã®æ­´å²çš„æ¤œè¨¼\n",
    "5. **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–**: ãƒªã‚¹ã‚¯èª¿æ•´å¾Œãƒªã‚¿ãƒ¼ãƒ³ã®æœ€å¤§åŒ–\n",
    "\n",
    "æ¬¡ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ `4_adjacent_spreads_trading_strategies.ipynb` ã§ã€å…·ä½“çš„ãªå–å¼•æˆ¦ç•¥ã®æ§‹ç¯‰ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}