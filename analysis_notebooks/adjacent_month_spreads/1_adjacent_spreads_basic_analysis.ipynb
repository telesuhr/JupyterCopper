{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMEéŠ…å…ˆç‰© éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ åŸºæœ¬åˆ†æ\n",
    "\n",
    "## æ¦‚è¦\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€LMEéŠ…å…ˆç‰©ã®éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆM1-M2ã€M2-M3ã€M3-M4ï¼‰ã®åŸºæœ¬åˆ†æã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "### åˆ†æå¯¾è±¡\n",
    "- **M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰**: ç¬¬1é™æœˆ - ç¬¬2é™æœˆ\n",
    "- **M2-M3ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰**: ç¬¬2é™æœˆ - ç¬¬3é™æœˆ  \n",
    "- **M3-M4ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰**: ç¬¬3é™æœˆ - ç¬¬4é™æœˆ\n",
    "\n",
    "### æœŸå¾…ã•ã‚Œã‚‹æˆæœ\n",
    "- éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®åŸºæœ¬çµ±è¨ˆé‡ã¨åˆ†å¸ƒç‰¹æ€§\n",
    "- å„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®æ™‚ç³»åˆ—æ¨ç§»ã¨ãƒˆãƒ¬ãƒ³ãƒ‰\n",
    "- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ°´æº–ã®å­£ç¯€æ€§ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "- ãƒªã‚¹ã‚¯ç‰¹æ€§ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š\n",
    "def get_db_connection():\n",
    "    \"\"\"PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æ¥ç¶šã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        engine = create_engine('postgresql://Yusuke@localhost:5432/lme_copper_db')\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return None\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
    "engine = get_db_connection()\n",
    "if engine:\n",
    "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ\")\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå¤±æ•—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_futures_data():\n",
    "    \"\"\"å…ˆç‰©ãƒ‡ãƒ¼ã‚¿ã®å–å¾—\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        trade_date,\n",
    "        contract_month,\n",
    "        close_price,\n",
    "        volume,\n",
    "        open_interest,\n",
    "        ric\n",
    "    FROM lme_copper_futures \n",
    "    WHERE contract_month IN (1, 2, 3, 4)\n",
    "        AND close_price IS NOT NULL\n",
    "        AND close_price > 0\n",
    "    ORDER BY trade_date, contract_month\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql(query, engine)\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    \n",
    "    print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†:\")\n",
    "    print(f\"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}\")\n",
    "    print(f\"   ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df['trade_date'].min()} ï½ {df['trade_date'].max()}\")\n",
    "    print(f\"   é™æœˆåˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:\")\n",
    "    for month in [1, 2, 3, 4]:\n",
    "        count = len(df[df['contract_month'] == month])\n",
    "        print(f\"     M{month}: {count:,} ãƒ¬ã‚³ãƒ¼ãƒ‰\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "futures_data = load_futures_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjacent_spreads(df):\n",
    "    \"\"\"éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®è¨ˆç®—\"\"\"\n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ”ãƒœãƒƒãƒˆã—ã¦é™æœˆåˆ¥ã‚«ãƒ©ãƒ ã«å¤‰æ›\n",
    "    pivot_df = df.pivot(index='trade_date', columns='contract_month', values='close_price')\n",
    "    \n",
    "    # ã‚«ãƒ©ãƒ åã‚’åˆ†ã‹ã‚Šã‚„ã™ãå¤‰æ›´\n",
    "    pivot_df.columns = [f'M{int(col)}' for col in pivot_df.columns]\n",
    "    \n",
    "    # éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚’è¨ˆç®—\n",
    "    spreads_df = pd.DataFrame(index=pivot_df.index)\n",
    "    \n",
    "    spreads_df['M1_price'] = pivot_df['M1']\n",
    "    spreads_df['M2_price'] = pivot_df['M2']\n",
    "    spreads_df['M3_price'] = pivot_df['M3']\n",
    "    spreads_df['M4_price'] = pivot_df['M4']\n",
    "    \n",
    "    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®è¨ˆç®—ï¼ˆå‰é™æœˆ - å¾Œé™æœˆï¼‰\n",
    "    spreads_df['M1_M2_spread'] = pivot_df['M1'] - pivot_df['M2']\n",
    "    spreads_df['M2_M3_spread'] = pivot_df['M2'] - pivot_df['M3']\n",
    "    spreads_df['M3_M4_spread'] = pivot_df['M3'] - pivot_df['M4']\n",
    "    \n",
    "    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰å¤‰åŒ–ç‡ï¼ˆæ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼‰\n",
    "    spreads_df['M1_M2_spread_change'] = spreads_df['M1_M2_spread'].pct_change()\n",
    "    spreads_df['M2_M3_spread_change'] = spreads_df['M2_M3_spread'].pct_change()\n",
    "    spreads_df['M3_M4_spread_change'] = spreads_df['M3_M4_spread'].pct_change()\n",
    "    \n",
    "    # NaNå€¤ã‚’é™¤å»\n",
    "    spreads_df = spreads_df.dropna()\n",
    "    \n",
    "    print(f\"ğŸ“ˆ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—å®Œäº†:\")\n",
    "    print(f\"   æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°: {len(spreads_df):,}\")\n",
    "    print(f\"   æ¬ æå€¤é™¤å»å¾ŒæœŸé–“: {spreads_df.index.min()} ï½ {spreads_df.index.max()}\")\n",
    "    \n",
    "    return spreads_df\n",
    "\n",
    "# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—\n",
    "spreads_data = calculate_adjacent_spreads(futures_data)\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­ç¢ºèª\n",
    "print(\"\\nğŸ“‹ è¨ˆç®—ã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘5æ—¥åˆ†ï¼‰:\")\n",
    "print(spreads_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åŸºæœ¬çµ±è¨ˆé‡ã¨ãƒ‡ãƒ¼ã‚¿æ¦‚è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_basic_statistics(df):\n",
    "    \"\"\"åŸºæœ¬çµ±è¨ˆé‡ã®è¨ˆç®—\"\"\"\n",
    "    spread_columns = ['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']\n",
    "    \n",
    "    stats_df = pd.DataFrame()\n",
    "    \n",
    "    for col in spread_columns:\n",
    "        spread_name = col.replace('_spread', '').replace('_', '-')\n",
    "        \n",
    "        stats_df[spread_name] = [\n",
    "            df[col].count(),           # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "            df[col].mean(),            # å¹³å‡\n",
    "            df[col].median(),          # ä¸­å¤®å€¤\n",
    "            df[col].std(),             # æ¨™æº–åå·®\n",
    "            df[col].min(),             # æœ€å°å€¤\n",
    "            df[col].max(),             # æœ€å¤§å€¤\n",
    "            df[col].quantile(0.25),    # ç¬¬1å››åˆ†ä½æ•°\n",
    "            df[col].quantile(0.75),    # ç¬¬3å››åˆ†ä½æ•°\n",
    "            df[col].skew(),            # æ­ªåº¦\n",
    "            df[col].kurtosis(),        # å°–åº¦\n",
    "        ]\n",
    "    \n",
    "    stats_df.index = ['ãƒ‡ãƒ¼ã‚¿æ•°', 'å¹³å‡', 'ä¸­å¤®å€¤', 'æ¨™æº–åå·®', 'æœ€å°å€¤', 'æœ€å¤§å€¤', \n",
    "                      'Q1(25%)', 'Q3(75%)', 'æ­ªåº¦', 'å°–åº¦']\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# åŸºæœ¬çµ±è¨ˆé‡ã‚’è¨ˆç®—\n",
    "basic_stats = calculate_basic_statistics(spreads_data)\n",
    "\n",
    "print(\"ğŸ“Š éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åŸºæœ¬çµ±è¨ˆé‡:\")\n",
    "print(\"=\" * 50)\n",
    "print(basic_stats.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®åˆ†å¸ƒç‰¹æ€§ã‚’è©³ç´°åˆ†æ\n",
    "def analyze_spread_characteristics(df):\n",
    "    \"\"\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ç‰¹æ€§ã®è©³ç´°åˆ†æ\"\"\"\n",
    "    spread_columns = ['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']\n",
    "    \n",
    "    print(\"\\nğŸ” éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ç‰¹æ€§åˆ†æ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for col in spread_columns:\n",
    "        spread_name = col.replace('_spread', '').replace('_', '-')\n",
    "        data = df[col]\n",
    "        \n",
    "        # æ­£å€¤ãƒ»è² å€¤ã®åˆ†å¸ƒ\n",
    "        positive_ratio = (data > 0).mean() * 100\n",
    "        negative_ratio = (data < 0).mean() * 100\n",
    "        zero_ratio = (data == 0).mean() * 100\n",
    "        \n",
    "        # æ¥µå€¤ã®é »åº¦\n",
    "        q95 = data.quantile(0.95)\n",
    "        q05 = data.quantile(0.05)\n",
    "        extreme_high = (data > q95).sum()\n",
    "        extreme_low = (data < q05).sum()\n",
    "        \n",
    "        print(f\"\\n{spread_name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        print(f\"  æ­£å€¤ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´ï¼‰: {positive_ratio:.1f}%\")\n",
    "        print(f\"  è² å€¤ï¼ˆãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰: {negative_ratio:.1f}%\")\n",
    "        print(f\"  ã‚¼ãƒ­ï¼ˆãƒ•ãƒ©ãƒƒãƒˆï¼‰: {zero_ratio:.1f}%\")\n",
    "        print(f\"  95%åˆ†ä½ç‚¹è¶…é: {extreme_high}å› ({extreme_high/len(data)*100:.1f}%)\")\n",
    "        print(f\"  5%åˆ†ä½ç‚¹æœªæº€: {extreme_low}å› ({extreme_low/len(data)*100:.1f}%)\")\n",
    "        print(f\"  å¤‰å‹•å¹…ï¼ˆMax-Minï¼‰: {data.max() - data.min():.2f} USD/t\")\n",
    "\n",
    "analyze_spread_characteristics(spreads_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ™‚ç³»åˆ—æ¨ç§»ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆ\n",
    "def plot_spread_timeseries(df):\n",
    "    \"\"\"éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆ\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        subplot_titles=('M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰', 'M2-M3ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰', 'M3-M4ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰'),\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    spreads = [\n",
    "        ('M1_M2_spread', 'M1-M2', 'blue'),\n",
    "        ('M2_M3_spread', 'M2-M3', 'red'),\n",
    "        ('M3_M4_spread', 'M3-M4', 'green')\n",
    "    ]\n",
    "    \n",
    "    for i, (col, name, color) in enumerate(spreads, 1):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=df[col],\n",
    "                name=f\"{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰\",\n",
    "                line=dict(color=color, width=1),\n",
    "                mode='lines'\n",
    "            ),\n",
    "            row=i, col=1\n",
    "        )\n",
    "        \n",
    "        # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ \n",
    "        fig.add_hline(\n",
    "            y=0, \n",
    "            line_dash=\"dash\", \n",
    "            line_color=\"black\", \n",
    "            line_width=1,\n",
    "            row=i, col=1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"LMEéŠ…å…ˆç‰© éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ™‚ç³»åˆ—æ¨ç§»\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Yè»¸ãƒ©ãƒ™ãƒ«\n",
    "    for i in range(1, 4):\n",
    "        fig.update_yaxes(title_text=\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=i, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=3, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º\n",
    "spread_chart = plot_spread_timeseries(spreads_data)\n",
    "spread_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "os.makedirs('../generated_images', exist_ok=True)\n",
    "spread_chart.write_image('../generated_images/adjacent_spreads_timeseries.png', \n",
    "                        width=1200, height=800, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ç§»å‹•å¹³å‡ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n",
    "def calculate_trend_analysis(df):\n",
    "    \"\"\"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™\"\"\"\n",
    "    spread_columns = ['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']\n",
    "    \n",
    "    trend_df = df.copy()\n",
    "    \n",
    "    for col in spread_columns:\n",
    "        # ç§»å‹•å¹³å‡\n",
    "        trend_df[f'{col}_ma5'] = df[col].rolling(window=5).mean()\n",
    "        trend_df[f'{col}_ma20'] = df[col].rolling(window=20).mean()\n",
    "        trend_df[f'{col}_ma60'] = df[col].rolling(window=60).mean()\n",
    "        \n",
    "        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ï¼ˆ20æ—¥ã€2Ïƒï¼‰\n",
    "        ma20 = trend_df[f'{col}_ma20']\n",
    "        std20 = df[col].rolling(window=20).std()\n",
    "        trend_df[f'{col}_bb_upper'] = ma20 + (std20 * 2)\n",
    "        trend_df[f'{col}_bb_lower'] = ma20 - (std20 * 2)\n",
    "        \n",
    "        # RSIï¼ˆ14æ—¥ï¼‰\n",
    "        delta = df[col].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        trend_df[f'{col}_rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return trend_df\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå®Ÿè¡Œ\n",
    "trend_data = calculate_trend_analysis(spreads_data)\n",
    "\n",
    "print(\"ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†ææŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¾ã—ãŸ:\")\n",
    "print(f\"   ç§»å‹•å¹³å‡: 5æ—¥ã€20æ—¥ã€60æ—¥\")\n",
    "print(f\"   ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰: 20æ—¥Â±2Ïƒ\")\n",
    "print(f\"   RSI: 14æ—¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãƒãƒ£ãƒ¼ãƒˆ\n",
    "def plot_technical_analysis(df, spread_col='M1_M2_spread', title='M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰'):\n",
    "    \"\"\"ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãƒãƒ£ãƒ¼ãƒˆ\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        row_heights=[0.7, 0.3],\n",
    "        subplot_titles=(f'{title} + ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™', 'RSI'),\n",
    "        vertical_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ + ç§»å‹•å¹³å‡ + ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ï¼‰\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[-252:],  # ç›´è¿‘1å¹´åˆ†\n",
    "            y=df[spread_col].iloc[-252:],\n",
    "            name=title,\n",
    "            line=dict(color='blue', width=1.5)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # ç§»å‹•å¹³å‡\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[-252:],\n",
    "            y=df[f'{spread_col}_ma20'].iloc[-252:],\n",
    "            name='MA20',\n",
    "            line=dict(color='orange', width=1)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[-252:],\n",
    "            y=df[f'{spread_col}_bb_upper'].iloc[-252:],\n",
    "            name='BB Upper',\n",
    "            line=dict(color='red', width=1, dash='dash'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[-252:],\n",
    "            y=df[f'{spread_col}_bb_lower'].iloc[-252:],\n",
    "            name='BB Lower',\n",
    "            line=dict(color='red', width=1, dash='dash'),\n",
    "            fill='tonexty',\n",
    "            fillcolor='rgba(255,0,0,0.1)',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # RSI\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index[-252:],\n",
    "            y=df[f'{spread_col}_rsi'].iloc[-252:],\n",
    "            name='RSI',\n",
    "            line=dict(color='purple', width=1.5)\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # RSIåŸºæº–ç·š\n",
    "    fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", line_width=1, row=2, col=1)\n",
    "    fig.add_hline(y=30, line_dash=\"dash\", line_color=\"blue\", line_width=1, row=2, col=1)\n",
    "    fig.add_hline(y=50, line_dash=\"dot\", line_color=\"gray\", line_width=1, row=2, col=1)\n",
    "    \n",
    "    # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", line_width=1, row=1, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f\"LMEéŠ…å…ˆç‰© {title} ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æï¼ˆç›´è¿‘1å¹´ï¼‰\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"RSI\", row=2, col=1, range=[0, 100])\n",
    "    fig.update_xaxes(title_text=\"æ—¥ä»˜\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ\n",
    "tech_chart = plot_technical_analysis(trend_data, 'M1_M2_spread', 'M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰')\n",
    "tech_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "tech_chart.write_image('../generated_images/m1_m2_spread_technical_analysis.png', \n",
    "                      width=1200, height=600, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒã¨ãƒªã‚¹ã‚¯åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒã®è©³ç´°åˆ†æ\n",
    "def plot_spread_distributions(df):\n",
    "    \"\"\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒã®å¯è¦–åŒ–\"\"\"\n",
    "    spread_columns = ['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰',\n",
    "            'ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒï¼ˆãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼‰',\n",
    "            'Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦æ€§æ¤œå®šï¼‰',\n",
    "            'ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ç›¸é–¢è¡Œåˆ—'\n",
    "        ),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    # 1. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "    for i, (col, name, color) in enumerate(zip(spread_columns, spread_names, colors)):\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=df[col],\n",
    "                name=f'{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰',\n",
    "                nbinsx=50,\n",
    "                opacity=0.7,\n",
    "                marker_color=color\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    for i, (col, name, color) in enumerate(zip(spread_columns, spread_names, colors)):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=df[col],\n",
    "                name=f'{name}',\n",
    "                marker_color=color,\n",
    "                boxpoints='outliers'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆM1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ã¿ï¼‰\n",
    "    from scipy.stats import probplot\n",
    "    theoretical_quantiles, sample_quantiles = probplot(df['M1_M2_spread'].dropna(), dist=\"norm\")\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=theoretical_quantiles,\n",
    "            y=sample_quantiles,\n",
    "            mode='markers',\n",
    "            name='M1-M2 Q-Q',\n",
    "            marker=dict(color='blue', size=4)\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # ç†è«–ç·šï¼ˆæ­£è¦åˆ†å¸ƒï¼‰\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[theoretical_quantiles.min(), theoretical_quantiles.max()],\n",
    "            y=[sample_quantiles.min(), sample_quantiles.max()],\n",
    "            mode='lines',\n",
    "            name='ç†è«–ç·š',\n",
    "            line=dict(color='red', dash='dash')\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. ç›¸é–¢è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "    corr_matrix = df[spread_columns].corr()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=corr_matrix.values,\n",
    "            x=spread_names,\n",
    "            y=spread_names,\n",
    "            colorscale='RdBu',\n",
    "            zmid=0,\n",
    "            text=np.round(corr_matrix.values, 3),\n",
    "            texttemplate=\"%{text}\",\n",
    "            textfont={\"size\": 12},\n",
    "            showscale=True\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†å¸ƒãƒ»ãƒªã‚¹ã‚¯åˆ†æ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    fig.update_xaxes(title_text=\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"é »åº¦\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"ç†è«–åˆ†ä½æ•°\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"ã‚µãƒ³ãƒ—ãƒ«åˆ†ä½æ•°\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# åˆ†å¸ƒåˆ†æãƒãƒ£ãƒ¼ãƒˆ\n",
    "dist_chart = plot_spread_distributions(spreads_data)\n",
    "dist_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "dist_chart.write_image('../generated_images/adjacent_spreads_distribution_analysis.png', \n",
    "                      width=1200, height=800, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­£è¦æ€§æ¤œå®šã¨çµ±è¨ˆçš„æ¤œå®š\n",
    "def statistical_tests(df):\n",
    "    \"\"\"çµ±è¨ˆçš„æ¤œå®šã®å®Ÿè¡Œ\"\"\"\n",
    "    spread_columns = ['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']\n",
    "    spread_names = ['M1-M2', 'M2-M3', 'M3-M4']\n",
    "    \n",
    "    print(\"ğŸ”¬ çµ±è¨ˆçš„æ¤œå®šçµæœ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    for col, name in zip(spread_columns, spread_names):\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        # Shapiro-Wilkæ­£è¦æ€§æ¤œå®š\n",
    "        if len(data) <= 5000:  # ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "        else:\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(data.sample(5000))\n",
    "        \n",
    "        # Jarque-Beraæ­£è¦æ€§æ¤œå®š\n",
    "        jb_stat, jb_p = stats.jarque_bera(data)\n",
    "        \n",
    "        # Kolmogorov-Smirnovæ­£è¦æ€§æ¤œå®š\n",
    "        ks_stat, ks_p = stats.kstest(data, 'norm', args=(data.mean(), data.std()))\n",
    "        \n",
    "        # Augmented Dickey-Fullerå˜ä½æ ¹æ¤œå®šï¼ˆå®šå¸¸æ€§ï¼‰\n",
    "        from statsmodels.tsa.stattools import adfuller\n",
    "        adf_result = adfuller(data)\n",
    "        \n",
    "        test_results[name] = {\n",
    "            'shapiro': (shapiro_stat, shapiro_p),\n",
    "            'jarque_bera': (jb_stat, jb_p),\n",
    "            'ks_test': (ks_stat, ks_p),\n",
    "            'adf': adf_result\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        print(f\"  Shapiro-Wilkæ­£è¦æ€§æ¤œå®š: çµ±è¨ˆé‡={shapiro_stat:.4f}, på€¤={shapiro_p:.4f}\")\n",
    "        print(f\"  Jarque-Beraæ­£è¦æ€§æ¤œå®š: çµ±è¨ˆé‡={jb_stat:.4f}, på€¤={jb_p:.4f}\")\n",
    "        print(f\"  K-Sæ­£è¦æ€§æ¤œå®š: çµ±è¨ˆé‡={ks_stat:.4f}, på€¤={ks_p:.4f}\")\n",
    "        print(f\"  ADFå˜ä½æ ¹æ¤œå®š: çµ±è¨ˆé‡={adf_result[0]:.4f}, på€¤={adf_result[1]:.4f}\")\n",
    "        \n",
    "        # è§£é‡ˆ\n",
    "        normal_tests = [shapiro_p, jb_p, ks_p]\n",
    "        if all(p < 0.05 for p in normal_tests):\n",
    "            print(f\"  â†’ æ­£è¦åˆ†å¸ƒã§ã¯ãªã„ï¼ˆå…¨æ¤œå®šã§p<0.05ï¼‰\")\n",
    "        elif any(p >= 0.05 for p in normal_tests):\n",
    "            print(f\"  â†’ æ­£è¦åˆ†å¸ƒã®å¯èƒ½æ€§ã‚ã‚Šï¼ˆä¸€éƒ¨æ¤œå®šã§pâ‰¥0.05ï¼‰\")\n",
    "        \n",
    "        if adf_result[1] < 0.05:\n",
    "            print(f\"  â†’ å®šå¸¸ç³»åˆ—ï¼ˆADFæ¤œå®šp<0.05ï¼‰\")\n",
    "        else:\n",
    "            print(f\"  â†’ éå®šå¸¸ç³»åˆ—ã®å¯èƒ½æ€§ï¼ˆADFæ¤œå®špâ‰¥0.05ï¼‰\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# çµ±è¨ˆçš„æ¤œå®šå®Ÿè¡Œ\n",
    "test_results = statistical_tests(spreads_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­£ç¯€æ€§ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­£ç¯€æ€§åˆ†æ\n",
    "def analyze_seasonality(df):\n",
    "    \"\"\"å­£ç¯€æ€§ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\"\"\"\n",
    "    seasonal_df = df.copy()\n",
    "    \n",
    "    # æ™‚é–“çš„ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "    seasonal_df['year'] = seasonal_df.index.year\n",
    "    seasonal_df['month'] = seasonal_df.index.month\n",
    "    seasonal_df['quarter'] = seasonal_df.index.quarter\n",
    "    seasonal_df['day_of_year'] = seasonal_df.index.dayofyear\n",
    "    seasonal_df['weekday'] = seasonal_df.index.weekday\n",
    "    \n",
    "    return seasonal_df\n",
    "\n",
    "def plot_seasonality_analysis(df):\n",
    "    \"\"\"å­£ç¯€æ€§åˆ†æãƒãƒ£ãƒ¼ãƒˆ\"\"\"\n",
    "    seasonal_data = analyze_seasonality(df)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ æœˆåˆ¥å¹³å‡',\n",
    "            'M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ å››åŠæœŸåˆ¥åˆ†å¸ƒ',\n",
    "            'M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ å¹´åˆ¥æ¨ç§»',\n",
    "            'æ›œæ—¥åˆ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ç‰¹æ€§'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 1. æœˆåˆ¥å¹³å‡\n",
    "    monthly_avg = seasonal_data.groupby('month')['M1_M2_spread'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=monthly_avg['month'],\n",
    "            y=monthly_avg['mean'],\n",
    "            error_y=dict(type='data', array=monthly_avg['std']),\n",
    "            mode='lines+markers',\n",
    "            name='æœˆåˆ¥å¹³å‡',\n",
    "            line=dict(color='blue')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. å››åŠæœŸåˆ¥ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        quarter_data = seasonal_data[seasonal_data['quarter'] == quarter]['M1_M2_spread']\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=quarter_data,\n",
    "                name=f'Q{quarter}',\n",
    "                boxpoints='outliers'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. å¹´åˆ¥å¹³å‡æ¨ç§»\n",
    "    yearly_avg = seasonal_data.groupby('year')['M1_M2_spread'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=yearly_avg['year'],\n",
    "            y=yearly_avg['mean'],\n",
    "            error_y=dict(type='data', array=yearly_avg['std']),\n",
    "            mode='lines+markers',\n",
    "            name='å¹´åˆ¥å¹³å‡',\n",
    "            line=dict(color='red')\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. æ›œæ—¥åˆ¥åˆ†æ\n",
    "    weekday_avg = seasonal_data.groupby('weekday')['M1_M2_spread'].agg(['mean', 'std']).reset_index()\n",
    "    weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']\n",
    "    weekday_avg['weekday_name'] = [weekday_names[i] for i in weekday_avg['weekday']]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=weekday_avg['weekday_name'],\n",
    "            y=weekday_avg['mean'],\n",
    "            error_y=dict(type='data', array=weekday_avg['std']),\n",
    "            name='æ›œæ—¥åˆ¥å¹³å‡',\n",
    "            marker_color='green'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ å­£ç¯€æ€§ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\",\n",
    "            x=0.5,\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # è»¸ãƒ©ãƒ™ãƒ«æ›´æ–°\n",
    "    fig.update_xaxes(title_text=\"æœˆ\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"å¹³å‡ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"å¹´\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"å¹³å‡ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"æ›œæ—¥\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"å¹³å‡ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ (USD/t)\", row=2, col=2)\n",
    "    \n",
    "    return fig, seasonal_data\n",
    "\n",
    "# å­£ç¯€æ€§åˆ†æå®Ÿè¡Œ\n",
    "seasonality_chart, seasonal_data = plot_seasonality_analysis(spreads_data)\n",
    "seasonality_chart.show()\n",
    "\n",
    "# ç”»åƒä¿å­˜\n",
    "seasonality_chart.write_image('../generated_images/adjacent_spreads_seasonality_analysis.png', \n",
    "                             width=1200, height=700, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­£ç¯€æ€§ã®çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š\n",
    "def test_seasonality_significance(seasonal_data):\n",
    "    \"\"\"å­£ç¯€æ€§ã®çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œå®š\"\"\"\n",
    "    print(\"ğŸ—“ï¸ å­£ç¯€æ€§çµ±è¨ˆçš„æ¤œå®š:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ANOVAæ¤œå®šï¼ˆæœˆåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—é–“å·®ç•°ï¼‰\n",
    "    monthly_groups = [seasonal_data[seasonal_data['month'] == i]['M1_M2_spread'].dropna() \n",
    "                     for i in range(1, 13)]\n",
    "    \n",
    "    f_stat, p_value = stats.f_oneway(*monthly_groups)\n",
    "    print(f\"æœˆåˆ¥ANOVAæ¤œå®š:\")\n",
    "    print(f\"  Fçµ±è¨ˆé‡: {f_stat:.4f}\")\n",
    "    print(f\"  på€¤: {p_value:.4f}\")\n",
    "    print(f\"  çµæœ: {'æœˆåˆ¥ã«æœ‰æ„å·®ã‚ã‚Š' if p_value < 0.05 else 'æœˆåˆ¥ã«æœ‰æ„å·®ãªã—'}\")\n",
    "    \n",
    "    # å››åŠæœŸåˆ¥ANOVAæ¤œå®š\n",
    "    quarterly_groups = [seasonal_data[seasonal_data['quarter'] == i]['M1_M2_spread'].dropna() \n",
    "                       for i in range(1, 5)]\n",
    "    \n",
    "    f_stat_q, p_value_q = stats.f_oneway(*quarterly_groups)\n",
    "    print(f\"\\nå››åŠæœŸåˆ¥ANOVAæ¤œå®š:\")\n",
    "    print(f\"  Fçµ±è¨ˆé‡: {f_stat_q:.4f}\")\n",
    "    print(f\"  på€¤: {p_value_q:.4f}\")\n",
    "    print(f\"  çµæœ: {'å››åŠæœŸåˆ¥ã«æœ‰æ„å·®ã‚ã‚Š' if p_value_q < 0.05 else 'å››åŠæœŸåˆ¥ã«æœ‰æ„å·®ãªã—'}\")\n",
    "    \n",
    "    # æ›œæ—¥åˆ¥ANOVAæ¤œå®š\n",
    "    weekday_groups = [seasonal_data[seasonal_data['weekday'] == i]['M1_M2_spread'].dropna() \n",
    "                     for i in range(7)]\n",
    "    \n",
    "    f_stat_w, p_value_w = stats.f_oneway(*weekday_groups)\n",
    "    print(f\"\\næ›œæ—¥åˆ¥ANOVAæ¤œå®š:\")\n",
    "    print(f\"  Fçµ±è¨ˆé‡: {f_stat_w:.4f}\")\n",
    "    print(f\"  på€¤: {p_value_w:.4f}\")\n",
    "    print(f\"  çµæœ: {'æ›œæ—¥åˆ¥ã«æœ‰æ„å·®ã‚ã‚Š' if p_value_w < 0.05 else 'æ›œæ—¥åˆ¥ã«æœ‰æ„å·®ãªã—'}\")\n",
    "    \n",
    "    # æœˆåˆ¥çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "    print(f\"\\nğŸ“ˆ æœˆåˆ¥çµ±è¨ˆã‚µãƒãƒªãƒ¼:\")\n",
    "    monthly_stats = seasonal_data.groupby('month')['M1_M2_spread'].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(4)\n",
    "    \n",
    "    monthly_stats.index = [f'{i}æœˆ' for i in monthly_stats.index]\n",
    "    print(monthly_stats)\n",
    "    \n",
    "    return {\n",
    "        'monthly_anova': (f_stat, p_value),\n",
    "        'quarterly_anova': (f_stat_q, p_value_q),\n",
    "        'weekday_anova': (f_stat_w, p_value_w),\n",
    "        'monthly_stats': monthly_stats\n",
    "    }\n",
    "\n",
    "# å­£ç¯€æ€§æœ‰æ„æ€§æ¤œå®šå®Ÿè¡Œ\n",
    "seasonality_tests = test_seasonality_significance(seasonal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åˆ†æçµæœã‚µãƒãƒªãƒ¼ã¨æ´å¯Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŒ…æ‹¬çš„åˆ†æã‚µãƒãƒªãƒ¼\n",
    "def generate_analysis_summary(spreads_data, basic_stats, seasonality_tests):\n",
    "    \"\"\"åŒ…æ‹¬çš„åˆ†æã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ LMEéŠ…å…ˆç‰© éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†æã‚µãƒãƒªãƒ¼\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nğŸ”¢ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:\")\n",
    "    print(f\"  åˆ†ææœŸé–“: {spreads_data.index.min().strftime('%Y-%m-%d')} ï½ {spreads_data.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(spreads_data):,}\")\n",
    "    print(f\"  åˆ†æå¯¾è±¡: M1-M2, M2-M3, M3-M4 éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š åŸºæœ¬çµ±è¨ˆç‰¹æ€§:\")\n",
    "    for col in ['M1-M2', 'M2-M3', 'M3-M4']:\n",
    "        mean_val = basic_stats.loc['å¹³å‡', col]\n",
    "        std_val = basic_stats.loc['æ¨™æº–åå·®', col]\n",
    "        skew_val = basic_stats.loc['æ­ªåº¦', col]\n",
    "        \n",
    "        print(f\"  {col}ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰:\")\n",
    "        print(f\"    å¹³å‡: {mean_val:.2f} USD/t\")\n",
    "        print(f\"    æ¨™æº–åå·®: {std_val:.2f} USD/t\")\n",
    "        print(f\"    æ­ªåº¦: {skew_val:.3f} ({'å³æ­ªã¿' if skew_val > 0 else 'å·¦æ­ªã¿' if skew_val < 0 else 'å¯¾ç§°'})\") \n",
    "    \n",
    "    print(f\"\\nğŸ¯ ä¸»è¦ç™ºè¦‹äº‹é …:\")\n",
    "    \n",
    "    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ°´æº–ã®ç‰¹å¾´\n",
    "    m1_m2_positive = (spreads_data['M1_M2_spread'] > 0).mean() * 100\n",
    "    m2_m3_positive = (spreads_data['M2_M3_spread'] > 0).mean() * 100\n",
    "    m3_m4_positive = (spreads_data['M3_M4_spread'] > 0).mean() * 100\n",
    "    \n",
    "    print(f\"  1. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘æ€§:\")\n",
    "    print(f\"     M1-M2: {m1_m2_positive:.1f}%ãŒæ­£å€¤ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´å‚¾å‘ï¼‰\")\n",
    "    print(f\"     M2-M3: {m2_m3_positive:.1f}%ãŒæ­£å€¤ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´å‚¾å‘ï¼‰\")\n",
    "    print(f\"     M3-M4: {m3_m4_positive:.1f}%ãŒæ­£å€¤ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´å‚¾å‘ï¼‰\")\n",
    "    \n",
    "    # ç›¸é–¢é–¢ä¿‚\n",
    "    corr_m1m2_m2m3 = spreads_data['M1_M2_spread'].corr(spreads_data['M2_M3_spread'])\n",
    "    corr_m2m3_m3m4 = spreads_data['M2_M3_spread'].corr(spreads_data['M3_M4_spread'])\n",
    "    \n",
    "    print(f\"\\n  2. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰é–“ç›¸é–¢:\")\n",
    "    print(f\"     M1-M2 vs M2-M3: {corr_m1m2_m2m3:.3f}\")\n",
    "    print(f\"     M2-M3 vs M3-M4: {corr_m2m3_m3m4:.3f}\")\n",
    "    \n",
    "    # å­£ç¯€æ€§\n",
    "    monthly_anova_p = seasonality_tests['monthly_anova'][1]\n",
    "    print(f\"\\n  3. å­£ç¯€æ€§:\")\n",
    "    print(f\"     æœˆåˆ¥æœ‰æ„å·®: {'ã‚ã‚Š' if monthly_anova_p < 0.05 else 'ãªã—'} (p={monthly_anova_p:.4f})\")\n",
    "    \n",
    "    # æœ€ã‚‚å¤‰å‹•ãŒå¤§ãã„æœŸé–“\n",
    "    spreads_data_with_vol = spreads_data.copy()\n",
    "    spreads_data_with_vol['year'] = spreads_data_with_vol.index.year\n",
    "    yearly_vol = spreads_data_with_vol.groupby('year')['M1_M2_spread'].std()\n",
    "    high_vol_year = yearly_vol.idxmax()\n",
    "    low_vol_year = yearly_vol.idxmin()\n",
    "    \n",
    "    print(f\"\\n  4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹æ€§:\")\n",
    "    print(f\"     æœ€é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¹´: {high_vol_year} ({yearly_vol[high_vol_year]:.2f})\")\n",
    "    print(f\"     æœ€ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¹´: {low_vol_year} ({yearly_vol[low_vol_year]:.2f})\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ æŠ•è³‡ãƒ»å–å¼•ã¸ã®ç¤ºå”†:\")\n",
    "    print(f\"  â€¢ éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã¯ä¸»ã«ã‚³ãƒ³ã‚¿ãƒ³ã‚´çŠ¶æ…‹ã§æ¨ç§»\")\n",
    "    print(f\"  â€¢ M1-M2ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãŒæœ€ã‚‚å¤‰å‹•ãŒå¤§ããã€æµå‹•æ€§ã‚‚é«˜ã„\")\n",
    "    print(f\"  â€¢ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰é–“ã«ä¸€å®šã®ç›¸é–¢ãŒã‚ã‚Šã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåŠ¹æœã®æ¤œè¨ãŒå¿…è¦\")\n",
    "    \n",
    "    if monthly_anova_p < 0.05:\n",
    "        best_month = seasonality_tests['monthly_stats']['mean'].idxmax()\n",
    "        worst_month = seasonality_tests['monthly_stats']['mean'].idxmin()\n",
    "        print(f\"  â€¢ å­£ç¯€æ€§ã‚ã‚Š: {best_month}ãŒæœ€é«˜ã€{worst_month}ãŒæœ€ä½\")\n",
    "    \n",
    "    print(f\"  â€¢ ãƒªã‚¹ã‚¯ç®¡ç†ã«ã¯æ¨™æº–åå·®ã®2-3å€ã‚’ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹æ°´æº–ã¨ã—ã¦è¨­å®šæ¨å¥¨\")\n",
    "    \n",
    "    return {\n",
    "        'data_period': (spreads_data.index.min(), spreads_data.index.max()),\n",
    "        'sample_size': len(spreads_data),\n",
    "        'spread_characteristics': {\n",
    "            'M1_M2_positive_ratio': m1_m2_positive,\n",
    "            'M2_M3_positive_ratio': m2_m3_positive,\n",
    "            'M3_M4_positive_ratio': m3_m4_positive\n",
    "        },\n",
    "        'correlations': {\n",
    "            'M1M2_vs_M2M3': corr_m1m2_m2m3,\n",
    "            'M2M3_vs_M3M4': corr_m2m3_m3m4\n",
    "        },\n",
    "        'seasonality_significant': monthly_anova_p < 0.05,\n",
    "        'volatility_years': {\n",
    "            'highest': (high_vol_year, yearly_vol[high_vol_year]),\n",
    "            'lowest': (low_vol_year, yearly_vol[low_vol_year])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ã‚µãƒãƒªãƒ¼ç”Ÿæˆ\n",
    "analysis_summary = generate_analysis_summary(spreads_data, basic_stats, seasonality_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æçµæœã‚’CSVã§ä¿å­˜\n",
    "def save_analysis_results(spreads_data, basic_stats, analysis_summary):\n",
    "    \"\"\"åˆ†æçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\"\"\"\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "    os.makedirs('../analysis_results/adjacent_spreads', exist_ok=True)\n",
    "    \n",
    "    # 1. åŸºæœ¬çµ±è¨ˆé‡\n",
    "    basic_stats.to_csv('../analysis_results/adjacent_spreads/basic_statistics.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # 2. æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿\n",
    "    spreads_data.to_csv('../analysis_results/adjacent_spreads/spread_timeseries.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # 3. æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³\n",
    "    returns_data = spreads_data[['M1_M2_spread_change', 'M2_M3_spread_change', 'M3_M4_spread_change']].copy()\n",
    "    returns_data.to_csv('../analysis_results/adjacent_spreads/spread_returns.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # 4. ç›¸é–¢è¡Œåˆ—\n",
    "    correlation_matrix = spreads_data[['M1_M2_spread', 'M2_M3_spread', 'M3_M4_spread']].corr()\n",
    "    correlation_matrix.to_csv('../analysis_results/adjacent_spreads/correlation_matrix.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # 5. åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆJSONï¼‰\n",
    "    import json\n",
    "    \n",
    "    # æ—¥ä»˜ã‚’JSON serializableå½¢å¼ã«å¤‰æ›\n",
    "    summary_for_json = analysis_summary.copy()\n",
    "    summary_for_json['data_period'] = [\n",
    "        analysis_summary['data_period'][0].strftime('%Y-%m-%d'),\n",
    "        analysis_summary['data_period'][1].strftime('%Y-%m-%d')\n",
    "    ]\n",
    "    \n",
    "    with open('../analysis_results/adjacent_spreads/analysis_summary.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary_for_json, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ:\")\n",
    "    print(f\"  ğŸ“ˆ åŸºæœ¬çµ±è¨ˆé‡: ../analysis_results/adjacent_spreads/basic_statistics.csv\")\n",
    "    print(f\"  ğŸ“Š æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿: ../analysis_results/adjacent_spreads/spread_timeseries.csv\")\n",
    "    print(f\"  ğŸ“‰ æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: ../analysis_results/adjacent_spreads/spread_returns.csv\")\n",
    "    print(f\"  ğŸ”— ç›¸é–¢è¡Œåˆ—: ../analysis_results/adjacent_spreads/correlation_matrix.csv\")\n",
    "    print(f\"  ğŸ“‹ åˆ†æã‚µãƒãƒªãƒ¼: ../analysis_results/adjacent_spreads/analysis_summary.json\")\n",
    "\n",
    "# åˆ†æçµæœä¿å­˜\n",
    "save_analysis_results(spreads_data, basic_stats, analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "ã“ã®åŸºæœ¬åˆ†æã«ã‚ˆã‚Šã€LMEéŠ…å…ˆç‰©ã®éš£æœˆé–“ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®ç‰¹æ€§ã‚’æŠŠæ¡ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "### ä¸»è¦ç™ºè¦‹äº‹é …\n",
    "1. **ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘æ€§**: ä¸»ã«ã‚³ãƒ³ã‚¿ãƒ³ã‚´çŠ¶æ…‹ã§æ¨ç§»\n",
    "2. **ç›¸é–¢æ§‹é€ **: éš£æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰é–“ã«ä¸€å®šã®ç›¸é–¢é–¢ä¿‚\n",
    "3. **å­£ç¯€æ€§**: çµ±è¨ˆçš„ã«æœ‰æ„ãªæœˆåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­˜åœ¨\n",
    "4. **ãƒªã‚¹ã‚¯ç‰¹æ€§**: å¹´ã«ã‚ˆã£ã¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«å¤§ããªå·®\n",
    "\n",
    "### æ¬¡ã®åˆ†æã‚¹ãƒ†ãƒƒãƒ—\n",
    "1. **é«˜åº¦ãªæ™‚ç³»åˆ—åˆ†æ**: ARIMA/GARCHãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬\n",
    "2. **æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«**: ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜\n",
    "3. **å–å¼•æˆ¦ç•¥é–‹ç™º**: çµ±è¨ˆçš„è£å®šã¨ãƒšã‚¢ãƒˆãƒ¬ãƒ¼ãƒ‰\n",
    "4. **ãƒªã‚¹ã‚¯ç®¡ç†**: VaRã¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ\n",
    "5. **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**: å®Ÿéš›ã®å–å¼•æˆ¦ç•¥ã®æ¤œè¨¼\n",
    "\n",
    "æ¬¡ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ `2_adjacent_spreads_correlation_analysis.ipynb` ã§ã€ã‚ˆã‚Šè©³ç´°ãªç›¸é–¢åˆ†æã¨å…±å’Œåˆ†ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}