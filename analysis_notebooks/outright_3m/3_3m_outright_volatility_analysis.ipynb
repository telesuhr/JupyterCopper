{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LME銅3M先物 - ボラティリティ分析\n",
    "\n",
    "## 概要\n",
    "LME銅3M先物のボラティリティ特性を包括的に分析します。\n",
    "\n",
    "### 分析内容\n",
    "1. ボラティリティサーフェス分析\n",
    "2. GARCHモデルでのボラティリティモデリング\n",
    "3. ボラティリティクラスタリング\n",
    "4. リスクメトリクス計算\n",
    "5. ボラティリティスマイル分析\n",
    "6. ボラティリティスピルオーバー効果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォント設定\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# データベース接続\n",
    "engine = create_engine('postgresql://Yusuke@localhost:5432/lme_copper_db')\n",
    "\n",
    "print(\"=== LME銅3M先物ボラティリティ分析システム ===")\n",
    "print(\"データベース接続完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データ読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LME銅3M先物データの読み込み\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    date,\n",
    "    m3_price as price,\n",
    "    m3_volume as volume\n",
    "FROM lme_copper_futures\n",
    "WHERE m3_price IS NOT NULL\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# リターン計算\n",
    "df['returns'] = df['price'].pct_change()\n",
    "df['log_returns'] = np.log(df['price'] / df['price'].shift(1))\n",
    "df['squared_returns'] = df['returns'] ** 2\n",
    "df['abs_returns'] = df['returns'].abs()\n",
    "\n",
    "# 欠損値除去\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"データ期間: {df.index.min()} - {df.index.max()}\")\n",
    "print(f\"総レコード数: {len(df):,}\")\n",
    "\n",
    "# 基本統計\n",
    "print(\"\\n=== リターン統計 ===")\n",
    "print(f\"平均日次リターン: {df['returns'].mean():.6f}\")\n",
    "print(f\"日次ボラティリティ: {df['returns'].std():.6f}\")\n",
    "print(f\"年率ボラティリティ: {df['returns'].std() * np.sqrt(252):.4f}\")\n",
    "print(f\"最大ドローダウン: {df['returns'].min():.4f}\")\n",
    "print(f\"最大アップ: {df['returns'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ボラティリティサーフェス分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローリングウィンドウボラティリティ計算\n",
    "windows = [5, 10, 20, 60, 120]\n",
    "\n",
    "for window in windows:\n",
    "    df[f'vol_{window}d'] = df['returns'].rolling(window=window).std() * np.sqrt(252)\n",
    "    df[f'vol_{window}d_abs'] = df['abs_returns'].rolling(window=window).mean() * np.sqrt(252) * np.sqrt(np.pi/2)\n",
    "\n",
    "print(\"ボラティリティ時系列計算完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティサーフェス可視化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 価格時系列\n",
    "axes[0, 0].plot(df.index, df['price'], linewidth=1)\n",
    "axes[0, 0].set_title('LME Copper 3M Price')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 日次リターン\n",
    "axes[0, 1].plot(df.index, df['returns'], linewidth=0.5, alpha=0.7)\n",
    "axes[0, 1].set_title('Daily Returns')\n",
    "axes[0, 1].set_ylabel('Returns')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ローリングボラティリティ時系列\n",
    "axes[1, 0].plot(df.index, df['vol_20d'], label='20D Vol', linewidth=1)\n",
    "axes[1, 0].plot(df.index, df['vol_60d'], label='60D Vol', linewidth=1)\n",
    "axes[1, 0].plot(df.index, df['vol_120d'], label='120D Vol', linewidth=1)\n",
    "axes[1, 0].set_title('Rolling Volatility')\n",
    "axes[1, 0].set_ylabel('Annualized Volatility')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ボラティリティ散布図\n",
    "axes[1, 1].hist(df['vol_20d'].dropna(), bins=50, alpha=0.7, density=True)\n",
    "axes[1, 1].set_title('20-Day Volatility Distribution')\n",
    "axes[1, 1].set_xlabel('Volatility')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GARCHモデルでのボラティリティモデリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARCHモデルのフィッティング\n",
    "# リターンデータの準備（パーセント形式でスケール）\n",
    "returns_pct = df['returns'].dropna() * 100\n",
    "\n",
    "# GARCH(1,1)モデル\n",
    "try:\n",
    "    garch_model = arch_model(returns_pct, vol='Garch', p=1, q=1, dist='normal')\n",
    "    garch_fit = garch_model.fit(disp='off')\n",
    "    \n",
    "    print(\"=== GARCH(1,1)モデル結果 ===")\n",
    "    print(garch_fit.summary())\n",
    "    \n",
    "    # ボラティリティ予測\n",
    "    garch_vol = garch_fit.conditional_volatility / 100  # パーセントから正規化\n",
    "    df.loc[garch_vol.index, 'garch_vol'] = garch_vol\n",
    "    \n",
    "    # 年率ボラティリティに変換\n",
    "    df['garch_vol_annual'] = df['garch_vol'] * np.sqrt(252)\n",
    "    \n",
    "    print(\"GARCHモデルフィッティング完了\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"GARCHモデルフィッティングエラー: {e}\")\n",
    "    # フォールバックとして簡単なEWMAモデルを使用\n",
    "    df['garch_vol_annual'] = df['returns'].ewm(com=0.06).std() * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARCHモデル結果の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# 実現ボラティリティ vs GARCHモデル\n",
    "recent_data = df.tail(252)\n",
    "\n",
    "ax1.plot(recent_data.index, recent_data['vol_20d'], label='20D Historical Vol', alpha=0.7)\n",
    "ax1.plot(recent_data.index, recent_data['garch_vol_annual'], label='GARCH Vol', alpha=0.8)\n",
    "ax1.set_title('Historical vs GARCH Volatility')\n",
    "ax1.set_ylabel('Annualized Volatility')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ボラティリティ残差分析\n",
    "vol_residuals = recent_data['vol_20d'] - recent_data['garch_vol_annual']\n",
    "ax2.plot(recent_data.index, vol_residuals, color='red', alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax2.set_title('Volatility Model Residuals')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ボラティリティクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティクラスタリングで市場レジーム識別\n",
    "vol_features = df[['vol_20d', 'vol_60d', 'vol_120d']].dropna()\n",
    "\n",
    "# データ正規化\n",
    "scaler = StandardScaler()\n",
    "vol_features_scaled = scaler.fit_transform(vol_features)\n",
    "\n",
    "# K-meansクラスタリング\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "vol_clusters = kmeans.fit_predict(vol_features_scaled)\n",
    "\n",
    "# クラスターラベルをデータフレームに追加\n",
    "vol_features_df = vol_features.copy()\n",
    "vol_features_df['cluster'] = vol_clusters\n",
    "\n",
    "# クラスター特性分析\n",
    "print(\"=== ボラティリティクラスター分析 ===")\n",
    "cluster_stats = vol_features_df.groupby('cluster').agg({\n",
    "    'vol_20d': ['mean', 'std', 'count'],\n",
    "    'vol_60d': ['mean', 'std'],\n",
    "    'vol_120d': ['mean', 'std']\n",
    "})\n",
    "\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = vol_features_df[vol_features_df['cluster'] == cluster]\n",
    "    print(f\"\\nクラスター {cluster}:\")\n",
    "    print(f\"  サンプル数: {len(cluster_data):,}\")\n",
    "    print(f\"  20Dボラティリティ: {cluster_data['vol_20d'].mean():.4f}\")\n",
    "    print(f\"  60Dボラティリティ: {cluster_data['vol_60d'].mean():.4f}\")\n",
    "    print(f\"  120Dボラティリティ: {cluster_data['vol_120d'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティクラスター可視化\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# クラスター別時系列\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = vol_features_df[vol_features_df['cluster'] == cluster]\n",
    "    ax1.scatter(cluster_data.index, cluster_data['vol_20d'], \n",
    "               c=colors[cluster], alpha=0.6, s=10, label=f'Cluster {cluster}')\n",
    "\n",
    "ax1.set_title('Volatility Clusters Over Time')\n",
    "ax1.set_ylabel('20D Volatility')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# クラスターごとのボラティリティ分布\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = vol_features_df[vol_features_df['cluster'] == cluster]\n",
    "    ax2.hist(cluster_data['vol_20d'], bins=20, alpha=0.6, \n",
    "            color=colors[cluster], label=f'Cluster {cluster}', density=True)\n",
    "\n",
    "ax2.set_title('Volatility Distribution by Cluster')\n",
    "ax2.set_xlabel('20D Volatility')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# クラスターセンター可視化\n",
    "ax3.scatter(vol_features_df['vol_20d'], vol_features_df['vol_60d'], \n",
    "           c=[colors[i] for i in vol_clusters], alpha=0.6, s=10)\n",
    "\n",
    "# クラスターセンターをプロット\n",
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "for i, center in enumerate(centers):\n",
    "    ax3.scatter(center[0], center[1], c='black', marker='x', s=200, linewidths=3)\n",
    "    ax3.text(center[0], center[1], f'C{i}', fontsize=12, ha='center', va='center')\n",
    "\n",
    "ax3.set_title('Volatility Clusters (20D vs 60D)')\n",
    "ax3.set_xlabel('20D Volatility')\n",
    "ax3.set_ylabel('60D Volatility')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# クラスターサイズ分布\n",
    "cluster_counts = vol_features_df['cluster'].value_counts().sort_index()\n",
    "ax4.bar(range(n_clusters), cluster_counts.values, color=colors[:n_clusters])\n",
    "ax4.set_title('Cluster Size Distribution')\n",
    "ax4.set_xlabel('Cluster')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. リスクメトリクス計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaRとESの計算\n",
    "def calculate_var_es(returns, confidence_levels=[0.95, 0.99]):\n",
    "    \"\"\"\n",
    "    Value at Risk (VaR) と Expected Shortfall (ES) を計算\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for conf_level in confidence_levels:\n",
    "        alpha = 1 - conf_level\n",
    "        \n",
    "        # ヒストリカルVaR\n",
    "        var_hist = np.percentile(returns, alpha * 100)\n",
    "        \n",
    "        # パラメトリックVaR（正規分布仮定）\n",
    "        var_param = stats.norm.ppf(alpha, returns.mean(), returns.std())\n",
    "        \n",
    "        # Expected Shortfall（CVaR）\n",
    "        es = returns[returns <= var_hist].mean()\n",
    "        \n",
    "        results[conf_level] = {\n",
    "            'VaR_Historical': var_hist,\n",
    "            'VaR_Parametric': var_param,\n",
    "            'Expected_Shortfall': es\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# リスクメトリクス計算\n",
    "risk_metrics = calculate_var_es(df['returns'].dropna())\n",
    "\n",
    "print(\"=== リスクメトリクス ===")\n",
    "for conf_level, metrics in risk_metrics.items():\n",
    "    print(f\"\\n信頼水準 {conf_level*100:.0f}%:\")\n",
    "    print(f\"  ヒストリカルVaR: {metrics['VaR_Historical']:.4f}\")\n",
    "    print(f\"  パラメトリックVaR: {metrics['VaR_Parametric']:.4f}\")\n",
    "    print(f\"  Expected Shortfall: {metrics['Expected_Shortfall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローリングVaRの計算\n",
    "def calculate_rolling_var(returns, window=252, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    ローリングVaRを計算\n",
    "    \"\"\"\n",
    "    alpha = 1 - confidence_level\n",
    "    rolling_var = returns.rolling(window=window).quantile(alpha)\n",
    "    return rolling_var\n",
    "\n",
    "# ローリングVaR計算\n",
    "df['var_95'] = calculate_rolling_var(df['returns'], window=252, confidence_level=0.95)\n",
    "df['var_99'] = calculate_rolling_var(df['returns'], window=252, confidence_level=0.99)\n",
    "\n",
    "# リスクメトリクス可視化\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# リターンとVaR\n",
    "recent_data = df.tail(504)  # 約2年分\n",
    "ax1.plot(recent_data.index, recent_data['returns'], alpha=0.7, linewidth=0.5, label='Returns')\n",
    "ax1.plot(recent_data.index, recent_data['var_95'], color='red', linewidth=1, label='VaR 95%')\n",
    "ax1.plot(recent_data.index, recent_data['var_99'], color='darkred', linewidth=1, label='VaR 99%')\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax1.set_title('Returns and Value at Risk')\n",
    "ax1.set_ylabel('Returns')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# VaRブリーチ分析\n",
    "var_breaches_95 = (recent_data['returns'] < recent_data['var_95']).sum()\n",
    "var_breaches_99 = (recent_data['returns'] < recent_data['var_99']).sum()\n",
    "total_days = len(recent_data.dropna())\n",
    "\n",
    "breach_rate_95 = var_breaches_95 / total_days\n",
    "breach_rate_99 = var_breaches_99 / total_days\n",
    "\n",
    "ax2.text(0.05, 0.9, f'VaR 95% ブリーチ: {var_breaches_95}回 ({breach_rate_95:.2%})', \n",
    "         transform=ax2.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax2.text(0.05, 0.8, f'VaR 99% ブリーチ: {var_breaches_99}回 ({breach_rate_99:.2%})', \n",
    "         transform=ax2.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax2.text(0.05, 0.7, f'理論ブリーチ率: 5% (95% VaR), 1% (99% VaR)', \n",
    "         transform=ax2.transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "# ブリーチポイントをハイライト\n",
    "breach_points_95 = recent_data[recent_data['returns'] < recent_data['var_95']]\n",
    "breach_points_99 = recent_data[recent_data['returns'] < recent_data['var_99']]\n",
    "\n",
    "ax2.scatter(breach_points_95.index, breach_points_95['returns'], \n",
    "           color='red', s=20, alpha=0.8, label='VaR 95% Breach')\n",
    "ax2.scatter(breach_points_99.index, breach_points_99['returns'], \n",
    "           color='darkred', s=30, alpha=0.8, label='VaR 99% Breach')\n",
    "\n",
    "ax2.plot(recent_data.index, recent_data['returns'], alpha=0.3, linewidth=0.5)\n",
    "ax2.set_title('VaR Breach Analysis')\n",
    "ax2.set_ylabel('Returns')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ボラティリティスマイル分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティスマイル分析\n",
    "def analyze_volatility_smile(returns, vol_surface_days=[10, 20, 60]):\n",
    "    \"\"\"\n",
    "    ボラティリティスマイルの簡易分析\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for days in vol_surface_days:\n",
    "        # ローリングボラティリティ計算\n",
    "        rolling_vol = returns.rolling(window=days).std() * np.sqrt(252)\n",
    "        \n",
    "        # 分位点別ボラティリティ\n",
    "        vol_percentiles = {}\n",
    "        for percentile in [5, 10, 25, 50, 75, 90, 95]:\n",
    "            vol_percentiles[percentile] = np.percentile(rolling_vol.dropna(), percentile)\n",
    "        \n",
    "        results[days] = vol_percentiles\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ボラティリティスマイル分析\n",
    "vol_smile_data = analyze_volatility_smile(df['returns'])\n",
    "\n",
    "print(\"=== ボラティリティスマイル分析 ===")\n",
    "for days, percentiles in vol_smile_data.items():\n",
    "    print(f\"\\n{days}日ボラティリティ分布:\")\n",
    "    for perc, vol in percentiles.items():\n",
    "        print(f\"  {perc}%タイル: {vol:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティスマイル可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ボラティリティサーフェス\n",
    "percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
    "days_list = list(vol_smile_data.keys())\n",
    "\n",
    "for i, perc in enumerate(percentiles):\n",
    "    vol_values = [vol_smile_data[days][perc] for days in days_list]\n",
    "    ax1.plot(days_list, vol_values, marker='o', label=f'{perc}%tile')\n",
    "\n",
    "ax1.set_title('Volatility Surface by Percentile')\n",
    "ax1.set_xlabel('Rolling Window (Days)')\n",
    "ax1.set_ylabel('Annualized Volatility')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ボラティリティスマイル（中央値と分散）\n",
    "medians = [vol_smile_data[days][50] for days in days_list]\n",
    "q25 = [vol_smile_data[days][25] for days in days_list]\n",
    "q75 = [vol_smile_data[days][75] for days in days_list]\n",
    "\n",
    "ax2.plot(days_list, medians, marker='o', linewidth=2, label='Median')\n",
    "ax2.fill_between(days_list, q25, q75, alpha=0.3, label='IQR')\n",
    "ax2.set_title('Volatility Smile (Median with IQR)')\n",
    "ax2.set_xlabel('Rolling Window (Days)')\n",
    "ax2.set_ylabel('Annualized Volatility')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 結果の保存とサマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボラティリティ分析結果の保存\n",
    "volatility_analysis = df[['price', 'returns', 'vol_20d', 'vol_60d', 'vol_120d', \n",
    "                         'garch_vol_annual', 'var_95', 'var_99']].copy()\n",
    "\n",
    "# クラスター情報を結合\n",
    "volatility_analysis = volatility_analysis.merge(\n",
    "    vol_features_df[['cluster']], \n",
    "    left_index=True, right_index=True, how='left'\n",
    ")\n",
    "\n",
    "# 欠損値除去\n",
    "volatility_analysis = volatility_analysis.dropna()\n",
    "\n",
    "print(f\"保存データ期間: {volatility_analysis.index.min()} - {volatility_analysis.index.max()}\")\n",
    "print(f\"保存レコード数: {len(volatility_analysis):,}\")\n",
    "\n",
    "# CSVファイルに保存\n",
    "volatility_analysis.to_csv('lme_copper_3m_volatility_analysis.csv')\n",
    "\n",
    "print(\"\\n=== ボラティリティ分析サマリー ===")\n",
    "print(f\"平均年率ボラティリティ: {df['returns'].std() * np.sqrt(252):.4f}\")\n",
    "print(f\"最大ボラティリティ (20D): {df['vol_20d'].max():.4f}\")\n",
    "print(f\"最小ボラティリティ (20D): {df['vol_20d'].min():.4f}\")\n",
    "print(f\"ボラティリティクラスター数: {n_clusters}\")\n",
    "print(f\"VaR 95%ブリーチ率: {breach_rate_95:.2%}\")\n",
    "print(f\"VaR 99%ブリーチ率: {breach_rate_99:.2%}\")\n",
    "\n",
    "print(\"\\nボラティリティ分析結果をCSVファイルに保存しました: lme_copper_3m_volatility_analysis.csv\")\n",
    "print(\"\\n=== LME銅3M先物ボラティリティ分析完了 ===")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}