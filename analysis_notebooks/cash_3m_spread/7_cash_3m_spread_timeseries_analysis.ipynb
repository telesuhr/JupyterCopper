{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LME銅 Cash/3Mスプレッド 時系列分析\n",
    "\n",
    "## 分析目的\n",
    "このノートブックは、LME銅Cash/3Mスプレッドの時系列特性を詳細に分析し、予測モデリングの基盤を構築します。\n",
    "\n",
    "### 学習目標:\n",
    "1. **定常性の理解**: スプレッドデータの統計的性質\n",
    "2. **自己相関の分析**: 過去の値と現在の値の関係\n",
    "3. **差分化の効果**: 非定常データを定常化する手法\n",
    "4. **モデル選択**: ARIMA等のパラメータ決定\n",
    "5. **予測精度**: 時系列予測の評価方法\n",
    "\n",
    "### 教科書的アプローチ:\n",
    "各ステップを小さく分割し、理論と実践を組み合わせて学習していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cash/3M スプレッド時系列分析\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scipy import stats\n",
    "\n",
    "# 時系列分析ライブラリ\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from arch import arch_model\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# データベース設定\n",
    "db_config = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'database': os.getenv('DB_NAME', 'lme_copper_db'),\n",
    "    'user': os.getenv('DB_USER', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'password'),\n",
    "    'port': os.getenv('DB_PORT', '5432')\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "\n",
    "# スタイル設定\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "print(\"Cash/3M スプレッド時系列分析\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: データ読み込みと基本的な可視化\n",
    "\n",
    "### 理論:\n",
    "時系列分析の第一歩は、データの基本的な特性を理解することです。\n",
    "- **トレンド**: 長期的な方向性\n",
    "- **季節性**: 定期的なパターン\n",
    "- **不規則変動**: ランダムな変動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ読み込み開始...\n",
      "\n",
      "🔍 lme_copper_pricesからデータ取得中...\n",
      "   直接スプレッドデータ取得失敗: (psycopg2.errors.UndefinedColumn) column \"close_price\" does not exist\n",
      "LINE 4:                     close_price as spread_value\n",
      "                            ^\n",
      "HINT:  Perhaps you meant to reference the column \"lme_copper_prices.last_price\" or the column \"lme_copper_prices.low_price\".\n",
      "\n",
      "[SQL: \n",
      "                SELECT \n",
      "                    trade_date,\n",
      "                    close_price as spread_value\n",
      "                FROM lme_copper_prices \n",
      "                WHERE ric_code = 'CMCU0-3'\n",
      "                ORDER BY trade_date\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "   コンポーネント計算失敗: (psycopg2.errors.UndefinedColumn) column \"close_price\" does not exist\n",
      "LINE 8:                     (SELECT trade_date, close_price FROM lme...\n",
      "                                                ^\n",
      "HINT:  Perhaps you meant to reference the column \"lme_copper_prices.last_price\" or the column \"lme_copper_prices.low_price\".\n",
      "\n",
      "[SQL: \n",
      "                SELECT \n",
      "                    p1.trade_date,\n",
      "                    p1.close_price as cash_price,\n",
      "                    p2.close_price as future_3m_price,\n",
      "                    (p1.close_price - p2.close_price) as spread_value\n",
      "                FROM \n",
      "                    (SELECT trade_date, close_price FROM lme_copper_prices WHERE ric_code = 'CMCU0') p1\n",
      "                INNER JOIN \n",
      "                    (SELECT trade_date, close_price FROM lme_copper_prices WHERE ric_code = 'CMCU3') p2\n",
      "                    ON p1.trade_date = p2.trade_date\n",
      "                ORDER BY p1.trade_date\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "\n",
      "🔍 lme_copper_futuresからデータ取得中...\n",
      "   直接スプレッドデータ取得失敗: (psycopg2.errors.UndefinedColumn) column \"ric_code\" does not exist\n",
      "LINE 6:                 WHERE ric_code = 'CMCU0-3'\n",
      "                              ^\n",
      "\n",
      "[SQL: \n",
      "                SELECT \n",
      "                    trade_date,\n",
      "                    close_price as spread_value\n",
      "                FROM lme_copper_futures \n",
      "                WHERE ric_code = 'CMCU0-3'\n",
      "                ORDER BY trade_date\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "   コンポーネント計算失敗: (psycopg2.errors.UndefinedColumn) column \"ric_code\" does not exist\n",
      "LINE 8: ...e_date, close_price FROM lme_copper_futures WHERE ric_code =...\n",
      "                                                             ^\n",
      "\n",
      "[SQL: \n",
      "                SELECT \n",
      "                    p1.trade_date,\n",
      "                    p1.close_price as cash_price,\n",
      "                    p2.close_price as future_3m_price,\n",
      "                    (p1.close_price - p2.close_price) as spread_value\n",
      "                FROM \n",
      "                    (SELECT trade_date, close_price FROM lme_copper_futures WHERE ric_code = 'CMCU0') p1\n",
      "                INNER JOIN \n",
      "                    (SELECT trade_date, close_price FROM lme_copper_futures WHERE ric_code = 'CMCU3') p2\n",
      "                    ON p1.trade_date = p2.trade_date\n",
      "                ORDER BY p1.trade_date\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "\n",
      "🎲 ダミーデータ生成中...\n",
      "✅ ダミーデータ生成完了: 1305 レコード\n",
      "期間: 2020-01-01 00:00:00 ～ 2024-12-31 00:00:00\n",
      "スプレッド範囲: -34.50 ～ 76.13\n",
      "\n",
      "📊 最終データセット: 1305 レコード\n",
      "            spread_value\n",
      "trade_date              \n",
      "2020-01-01     22.450712\n",
      "2020-01-02     13.027381\n",
      "2020-01-03     24.917993\n",
      "2020-01-06     38.149382\n",
      "2020-01-07     11.892826\n"
     ]
    }
   ],
   "source": [
    "def load_comprehensive_spread_data():\n",
    "    \"\"\"\n",
    "    複数のデータソースからスプレッドデータを読み込み\n",
    "    \"\"\"\n",
    "    print(\"データ読み込み開始...\")\n",
    "    \n",
    "    data_sources = [\n",
    "        {\n",
    "            'name': 'lme_copper_prices',\n",
    "            'spread_query': \"\"\"\n",
    "                SELECT \n",
    "                    trade_date,\n",
    "                    close_price as spread_value\n",
    "                FROM lme_copper_prices \n",
    "                WHERE ric_code = 'CMCU0-3'\n",
    "                ORDER BY trade_date\n",
    "            \"\"\",\n",
    "            'component_query': \"\"\"\n",
    "                SELECT \n",
    "                    p1.trade_date,\n",
    "                    p1.close_price as cash_price,\n",
    "                    p2.close_price as future_3m_price,\n",
    "                    (p1.close_price - p2.close_price) as spread_value\n",
    "                FROM \n",
    "                    (SELECT trade_date, close_price FROM lme_copper_prices WHERE ric_code = 'CMCU0') p1\n",
    "                INNER JOIN \n",
    "                    (SELECT trade_date, close_price FROM lme_copper_prices WHERE ric_code = 'CMCU3') p2\n",
    "                    ON p1.trade_date = p2.trade_date\n",
    "                ORDER BY p1.trade_date\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            'name': 'lme_copper_futures',\n",
    "            'spread_query': \"\"\"\n",
    "                SELECT \n",
    "                    trade_date,\n",
    "                    close_price as spread_value\n",
    "                FROM lme_copper_futures \n",
    "                WHERE ric_code = 'CMCU0-3'\n",
    "                ORDER BY trade_date\n",
    "            \"\"\",\n",
    "            'component_query': \"\"\"\n",
    "                SELECT \n",
    "                    p1.trade_date,\n",
    "                    p1.close_price as cash_price,\n",
    "                    p2.close_price as future_3m_price,\n",
    "                    (p1.close_price - p2.close_price) as spread_value\n",
    "                FROM \n",
    "                    (SELECT trade_date, close_price FROM lme_copper_futures WHERE ric_code = 'CMCU0') p1\n",
    "                INNER JOIN \n",
    "                    (SELECT trade_date, close_price FROM lme_copper_futures WHERE ric_code = 'CMCU3') p2\n",
    "                    ON p1.trade_date = p2.trade_date\n",
    "                ORDER BY p1.trade_date\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        for source in data_sources:\n",
    "            print(f\"\\n🔍 {source['name']}からデータ取得中...\")\n",
    "            \n",
    "            # 直接スプレッドデータを試行\n",
    "            try:\n",
    "                df = pd.read_sql(source['spread_query'], engine)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "                    df.set_index('trade_date', inplace=True)\n",
    "                    print(f\"✅ 直接スプレッドデータ: {len(df)} レコード\")\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                print(f\"   直接スプレッドデータ取得失敗: {e}\")\n",
    "            \n",
    "            # コンポーネントから計算を試行\n",
    "            try:\n",
    "                df = pd.read_sql(source['component_query'], engine)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "                    df.set_index('trade_date', inplace=True)\n",
    "                    print(f\"✅ コンポーネント計算: {len(df)} レコード\")\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                print(f\"   コンポーネント計算失敗: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ データベース接続失敗: {e}\")\n",
    "    \n",
    "    # フォールバック: ダミーデータ生成\n",
    "    print(\"\\n🎲 ダミーデータ生成中...\")\n",
    "    \n",
    "    date_range = pd.date_range(\n",
    "        start='2020-01-01', \n",
    "        end='2024-12-31', \n",
    "        freq='D'\n",
    "    )\n",
    "    \n",
    "    # 営業日のみにフィルタ（土日除外）\n",
    "    business_days = date_range[date_range.dayofweek < 5]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 現実的なスプレッドデータ生成\n",
    "    base_spread = 25  # ベーススプレッド\n",
    "    volatility = 15   # ボラティリティ\n",
    "    trend_component = np.linspace(-10, 10, len(business_days))\n",
    "    seasonal_component = 5 * np.sin(2 * np.pi * np.arange(len(business_days)) / 365.25)\n",
    "    noise = np.random.normal(0, volatility, len(business_days))\n",
    "    \n",
    "    spread_values = base_spread + trend_component + seasonal_component + noise\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'spread_value': spread_values\n",
    "    }, index=business_days)\n",
    "    \n",
    "    df.index.name = 'trade_date'\n",
    "    \n",
    "    print(f\"✅ ダミーデータ生成完了: {len(df)} レコード\")\n",
    "    print(f\"期間: {df.index.min()} ～ {df.index.max()}\")\n",
    "    print(f\"スプレッド範囲: {df['spread_value'].min():.2f} ～ {df['spread_value'].max():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# データ読み込み実行\n",
    "df = load_comprehensive_spread_data()\n",
    "print(f\"\\n📊 最終データセット: {len(df)} レコード\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 定常性の検定\n",
    "\n",
    "### 理論:\n",
    "時系列分析において**定常性**は重要な概念です：\n",
    "\n",
    "**定常時系列の条件:**\n",
    "1. 平均が時間によって変化しない\n",
    "2. 分散が時間によって変化しない  \n",
    "3. 共分散が時間差のみに依存する\n",
    "\n",
    "**検定方法:**\n",
    "- **ADF検定**: 帰無仮説「単位根あり（非定常）」\n",
    "- **KPSS検定**: 帰無仮説「定常」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spread_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# 元の時系列に対する定常性検定\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mspread_data\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m     spread_series = spread_data[\u001b[33m'\u001b[39m\u001b[33mspread_price\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# ADF検定\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'spread_data' is not defined"
     ]
    }
   ],
   "source": [
    "def adf_test(series, title=\"\"):\n",
    "    \"\"\"\n",
    "    ADF検定（拡張ディッキー・フラー検定）の実行\n",
    "    H0: 単位根あり（非定常）\n",
    "    H1: 単位根なし（定常）\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ADF検定結果: {title}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    \n",
    "    print(f\"ADF統計量: {result[0]:.6f}\")\n",
    "    print(f\"p値: {result[1]:.6f}\")\n",
    "    print(f\"使用ラグ数: {result[2]}\")\n",
    "    print(f\"観測数: {result[3]}\")\n",
    "    \n",
    "    print(\"\\n臨界値:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"\\t{key}: {value:.3f}\")\n",
    "    \n",
    "    # 結果の解釈\n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"\\n✅ 結果: p値 = {result[1]:.6f} < 0.05\")\n",
    "        print(\"帰無仮説を棄却 → 時系列は定常です\")\n",
    "    else:\n",
    "        print(f\"\\n❌ 結果: p値 = {result[1]:.6f} > 0.05\")\n",
    "        print(\"帰無仮説を棄却できない → 時系列は非定常です\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def kpss_test(series, title=\"\"):\n",
    "    \"\"\"\n",
    "    KPSS検定の実行\n",
    "    H0: 定常\n",
    "    H1: 非定常\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"KPSS検定結果: {title}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    result = kpss(series, regression='c')\n",
    "    \n",
    "    print(f\"KPSS統計量: {result[0]:.6f}\")\n",
    "    print(f\"p値: {result[1]:.6f}\")\n",
    "    print(f\"使用ラグ数: {result[2]}\")\n",
    "    \n",
    "    print(\"\\n臨界値:\")\n",
    "    for key, value in result[3].items():\n",
    "        print(f\"\\t{key}: {value:.3f}\")\n",
    "    \n",
    "    # 結果の解釈\n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"\\n❌ 結果: p値 = {result[1]:.6f} < 0.05\")\n",
    "        print(\"帰無仮説を棄却 → 時系列は非定常です\")\n",
    "    else:\n",
    "        print(f\"\\n✅ 結果: p値 = {result[1]:.6f} > 0.05\")\n",
    "        print(\"帰無仮説を棄却できない → 時系列は定常です\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 元の時系列に対する定常性検定\n",
    "if spread_data is not None:\n",
    "    spread_series = spread_data['spread_price']\n",
    "    \n",
    "    # ADF検定\n",
    "    adf_result = adf_test(spread_series, \"Cash/3M Spread (元データ)\")\n",
    "    \n",
    "    # KPSS検定\n",
    "    kpss_result = kpss_test(spread_series, \"Cash/3M Spread (元データ)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"定常性検定まとめ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"検定結果:\")\n",
    "    print(f\"ADF検定: {'定常' if adf_result[1] <= 0.05 else '非定常'}\")\n",
    "    print(f\"KPSS検定: {'定常' if kpss_result[1] > 0.05 else '非定常'}\")\n",
    "    \n",
    "    if adf_result[1] <= 0.05 and kpss_result[1] > 0.05:\n",
    "        print(\"\\n✅ 総合判定: 時系列は定常です\")\n",
    "    elif adf_result[1] > 0.05 and kpss_result[1] <= 0.05:\n",
    "        print(\"\\n❌ 総合判定: 時系列は非定常です\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 総合判定: 検定結果が矛盾しています。追加検証が必要です\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 自己相関関数 (ACF) と偏自己相関関数 (PACF) の分析\n",
    "\n",
    "### 理論:\n",
    "**自己相関関数 (ACF):**\n",
    "- 時系列と自分自身のラグ版との相関\n",
    "- MA(q)モデルのqを決定するのに使用\n",
    "\n",
    "**偏自己相関関数 (PACF):**\n",
    "- 中間のラグの影響を除いた直接的な相関\n",
    "- AR(p)モデルのpを決定するのに使用\n",
    "\n",
    "**パターン識別:**\n",
    "- AR(p): PACF がp次で急激に減衰、ACF は指数的減衰\n",
    "- MA(q): ACF がq次で急激に減衰、PACF は指数的減衰\n",
    "- ARMA(p,q): 両方とも指数的減衰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF/PACF分析\n",
    "if spread_data is not None:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "    \n",
    "    # 元データのACF\n",
    "    plot_acf(spread_series, ax=axes[0,0], lags=40, alpha=0.05)\n",
    "    axes[0,0].set_title('自己相関関数 (ACF) - 元データ', fontsize=12, fontweight='bold')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 元データのPACF\n",
    "    plot_pacf(spread_series, ax=axes[0,1], lags=40, alpha=0.05)\n",
    "    axes[0,1].set_title('偏自己相関関数 (PACF) - 元データ', fontsize=12, fontweight='bold')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 一次差分のACF（定常化のため）\n",
    "    spread_diff = spread_series.diff().dropna()\n",
    "    plot_acf(spread_diff, ax=axes[1,0], lags=40, alpha=0.05)\n",
    "    axes[1,0].set_title('自己相関関数 (ACF) - 一次差分', fontsize=12, fontweight='bold')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 一次差分のPACF\n",
    "    plot_pacf(spread_diff, ax=axes[1,1], lags=40, alpha=0.05)\n",
    "    axes[1,1].set_title('偏自己相関関数 (PACF) - 一次差分', fontsize=12, fontweight='bold')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 一次差分の定常性検定\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"一次差分データの定常性検定\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    adf_diff = adf_test(spread_diff, \"Cash/3M Spread (一次差分)\")\n",
    "    kpss_diff = kpss_test(spread_diff, \"Cash/3M Spread (一次差分)\")\n",
    "    \n",
    "    # 数値的な相関分析\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"相関分析サマリー\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 主要ラグの自己相関\n",
    "    from statsmodels.tsa.stattools import acf, pacf\n",
    "    \n",
    "    acf_values = acf(spread_diff, nlags=10, alpha=0.05)\n",
    "    pacf_values = pacf(spread_diff, nlags=10, alpha=0.05)\n",
    "    \n",
    "    print(\"主要ラグの自己相関 (一次差分):\")\n",
    "    for i in range(1, 6):\n",
    "        print(f\"ラグ{i}: ACF = {acf_values[0][i]:.3f}, PACF = {pacf_values[0][i]:.3f}\")\n",
    "    \n",
    "    # Ljung-Box検定（残差の独立性検定）\n",
    "    lb_test = acorr_ljungbox(spread_diff, lags=10, return_df=True)\n",
    "    print(f\"\\nLjung-Box検定 (残差の独立性):\")\n",
    "    print(f\"p値 (ラグ10): {lb_test['lb_pvalue'].iloc[-1]:.6f}\")\n",
    "    \n",
    "    if lb_test['lb_pvalue'].iloc[-1] > 0.05:\n",
    "        print(\"✅ 残差は独立（ホワイトノイズ的）\")\n",
    "    else:\n",
    "        print(\"❌ 残差に自己相関あり（追加モデリングが必要）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ARIMA モデルの選択と推定\n",
    "\n",
    "### 理論:\n",
    "**ARIMA(p,d,q) モデル:**\n",
    "- p: 自己回帰項の次数 (AR)\n",
    "- d: 差分の次数 (I: Integrated)\n",
    "- q: 移動平均項の次数 (MA)\n",
    "\n",
    "**モデル選択基準:**\n",
    "- **AIC (赤池情報量基準)**: 小さいほど良い\n",
    "- **BIC (ベイズ情報量基準)**: 小さいほど良い\n",
    "- **残差診断**: ホワイトノイズ性の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMAモデル選択のためのグリッドサーチ\n",
    "def evaluate_arima_model(data, arima_order):\n",
    "    \"\"\"\n",
    "    指定されたARIMAモデルを評価\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = ARIMA(data, order=arima_order)\n",
    "        fitted_model = model.fit()\n",
    "        return fitted_model.aic, fitted_model.bic, fitted_model\n",
    "    except:\n",
    "        return float('inf'), float('inf'), None\n",
    "\n",
    "# モデル比較のためのグリッドサーチ\n",
    "if spread_data is not None:\n",
    "    print(\"ARIMA モデル選択（グリッドサーチ）\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # パラメータ範囲\n",
    "    p_values = range(0, 4)  # AR項\n",
    "    d_values = range(0, 2)  # 差分\n",
    "    q_values = range(0, 4)  # MA項\n",
    "    \n",
    "    best_aic = float('inf')\n",
    "    best_bic = float('inf')\n",
    "    best_order_aic = None\n",
    "    best_order_bic = None\n",
    "    best_model = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p, d, q)\n",
    "                try:\n",
    "                    aic, bic, model = evaluate_arima_model(spread_series, order)\n",
    "                    results.append((order, aic, bic))\n",
    "                    \n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        best_order_aic = order\n",
    "                        best_model = model\n",
    "                    \n",
    "                    if bic < best_bic:\n",
    "                        best_bic = bic\n",
    "                        best_order_bic = order\n",
    "                        \n",
    "                    print(f\"ARIMA{order}: AIC={aic:.2f}, BIC={bic:.2f}\")\n",
    "                except:\n",
    "                    print(f\"ARIMA{order}: 収束せず\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"最適モデル\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"AIC最小: ARIMA{best_order_aic} (AIC={best_aic:.2f})\")\n",
    "    print(f\"BIC最小: ARIMA{best_order_bic} (BIC={best_bic:.2f})\")\n",
    "    \n",
    "    # 最適モデルの詳細結果\n",
    "    if best_model is not None:\n",
    "        print(f\"\\n最適モデル ARIMA{best_order_aic} の詳細:\")\n",
    "        print(best_model.summary())\n",
    "        \n",
    "        # 残差分析\n",
    "        residuals = best_model.resid\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # 残差の時系列プロット\n",
    "        axes[0,0].plot(residuals)\n",
    "        axes[0,0].set_title(f'残差時系列 - ARIMA{best_order_aic}', fontsize=12, fontweight='bold')\n",
    "        axes[0,0].axhline(y=0, color='red', linestyle='--')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 残差のヒストグラム\n",
    "        axes[0,1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "        axes[0,1].set_title('残差の分布', fontsize=12, fontweight='bold')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Q-Qプロット\n",
    "        from scipy.stats import probplot\n",
    "        probplot(residuals, dist=\"norm\", plot=axes[1,0])\n",
    "        axes[1,0].set_title('Q-Qプロット（正規性検定）', fontsize=12, fontweight='bold')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 残差のACF\n",
    "        plot_acf(residuals, ax=axes[1,1], lags=20, alpha=0.05)\n",
    "        axes[1,1].set_title('残差の自己相関', fontsize=12, fontweight='bold')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 残差診断統計\n",
    "        print(f\"\\n残差診断:\")\n",
    "        print(f\"残差の平均: {residuals.mean():.6f}\")\n",
    "        print(f\"残差の標準偏差: {residuals.std():.6f}\")\n",
    "        \n",
    "        # Jarque-Bera検定（正規性）\n",
    "        from scipy.stats import jarque_bera\n",
    "        jb_stat, jb_pvalue = jarque_bera(residuals)\n",
    "        print(f\"Jarque-Bera検定 (正規性): 統計量={jb_stat:.3f}, p値={jb_pvalue:.6f}\")\n",
    "        \n",
    "        if jb_pvalue > 0.05:\n",
    "            print(\"✅ 残差は正規分布に従う\")\n",
    "        else:\n",
    "            print(\"❌ 残差は正規分布に従わない\")\n",
    "        \n",
    "        # Ljung-Box検定（残差の独立性）\n",
    "        lb_test_resid = acorr_ljungbox(residuals, lags=10, return_df=True)\n",
    "        print(f\"Ljung-Box検定 (残差独立性): p値={lb_test_resid['lb_pvalue'].iloc[-1]:.6f}\")\n",
    "        \n",
    "        if lb_test_resid['lb_pvalue'].iloc[-1] > 0.05:\n",
    "            print(\"✅ 残差は独立（モデルは適切）\")\n",
    "        else:\n",
    "            print(\"❌ 残差に自己相関あり（モデル改善が必要）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 予測と評価\n",
    "\n",
    "### 理論:\n",
    "**予測評価指標:**\n",
    "- **MAE**: 平均絶対誤差\n",
    "- **RMSE**: 二乗平均平方根誤差  \n",
    "- **MAPE**: 平均絶対パーセント誤差\n",
    "- **方向性精度**: 上昇/下降の予測的中率\n",
    "\n",
    "**時系列クロスバリデーション:**\n",
    "- 時系列の順序を保持した分割\n",
    "- ウォークフォワード分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測と評価\n",
    "if spread_data is not None and best_model is not None:\n",
    "    # データ分割（最後の30日をテスト用）\n",
    "    test_size = 30\n",
    "    train_data = spread_series[:-test_size]\n",
    "    test_data = spread_series[-test_size:]\n",
    "    \n",
    "    print(f\"学習データ: {len(train_data)}日\")\n",
    "    print(f\"テストデータ: {len(test_data)}日\")\n",
    "    \n",
    "    # モデル再学習（学習データのみ）\n",
    "    train_model = ARIMA(train_data, order=best_order_aic)\n",
    "    fitted_train_model = train_model.fit()\n",
    "    \n",
    "    # 予測実行\n",
    "    forecast_result = fitted_train_model.forecast(steps=test_size, alpha=0.05)\n",
    "    forecast_values = forecast_result\n",
    "    \n",
    "    # 信頼区間取得\n",
    "    forecast_ci = fitted_train_model.get_forecast(steps=test_size, alpha=0.05)\n",
    "    conf_int = forecast_ci.conf_int()\n",
    "    \n",
    "    # 予測評価指標計算\n",
    "    mae = np.mean(np.abs(test_data - forecast_values))\n",
    "    rmse = np.sqrt(np.mean((test_data - forecast_values)**2))\n",
    "    mape = np.mean(np.abs((test_data - forecast_values) / test_data)) * 100\n",
    "    \n",
    "    # 方向性精度\n",
    "    actual_direction = np.sign(test_data.diff().dropna())\n",
    "    predicted_direction = np.sign(pd.Series(forecast_values, index=test_data.index).diff().dropna())\n",
    "    directional_accuracy = (actual_direction == predicted_direction).mean()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"予測精度評価\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"MAE (平均絶対誤差): {mae:.3f}\")\n",
    "    print(f\"RMSE (二乗平均平方根誤差): {rmse:.3f}\")\n",
    "    print(f\"MAPE (平均絶対パーセント誤差): {mape:.3f}%\")\n",
    "    print(f\"方向性精度: {directional_accuracy:.3f} ({directional_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # 予測結果の可視化\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "    \n",
    "    # 予測vs実績\n",
    "    ax1.plot(train_data.index[-60:], train_data[-60:], label='学習データ', color='blue', alpha=0.7)\n",
    "    ax1.plot(test_data.index, test_data, label='実際の値', color='green', linewidth=2)\n",
    "    ax1.plot(test_data.index, forecast_values, label='予測値', color='red', linewidth=2, linestyle='--')\n",
    "    \n",
    "    # 信頼区間\n",
    "    ax1.fill_between(test_data.index, \n",
    "                     conf_int.iloc[:, 0], \n",
    "                     conf_int.iloc[:, 1], \n",
    "                     color='red', alpha=0.2, label='95%信頼区間')\n",
    "    \n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax1.set_title(f'ARIMA{best_order_aic} 予測結果', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('スプレッド (USD/tonne)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 予測誤差\n",
    "    prediction_errors = test_data - forecast_values\n",
    "    ax2.plot(test_data.index, prediction_errors, marker='o', linestyle='-', color='red')\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "    ax2.set_title('予測誤差', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('誤差 (USD/tonne)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 誤差統計\n",
    "    print(f\"\\n予測誤差統計:\")\n",
    "    print(f\"誤差の平均: {prediction_errors.mean():.3f}\")\n",
    "    print(f\"誤差の標準偏差: {prediction_errors.std():.3f}\")\n",
    "    print(f\"最大正誤差: {prediction_errors.max():.3f}\")\n",
    "    print(f\"最大負誤差: {prediction_errors.min():.3f}\")\n",
    "    \n",
    "    # 信頼区間カバレッジ\n",
    "    coverage = ((test_data >= conf_int.iloc[:, 0]) & \n",
    "                (test_data <= conf_int.iloc[:, 1])).mean()\n",
    "    print(f\"95%信頼区間カバレッジ: {coverage:.3f} ({coverage*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 結果の解釈とまとめ\n",
    "\n",
    "### 時系列分析から得られた知見の整理\n",
    "分析結果をトレーディング戦略に活用するための総合的な解釈を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定常化データをDataFrameに保存（次のステップで使用）\n",
    "if spread_data is not None:\n",
    "    # 分析結果のまとめ\n",
    "    stationary_data = pd.DataFrame(index=spread_data.index)\n",
    "    stationary_data['original_spread'] = spread_data['spread_price']\n",
    "    stationary_data['diff_spread'] = spread_data['spread_price'].diff()\n",
    "    \n",
    "    # 移動統計（ローリング平均・標準偏差）\n",
    "    stationary_data['rolling_mean_20'] = spread_data['spread_price'].rolling(20).mean()\n",
    "    stationary_data['rolling_std_20'] = spread_data['spread_price'].rolling(20).std()\n",
    "    \n",
    "    # Z-score（標準化）\n",
    "    stationary_data['zscore'] = (spread_data['spread_price'] - stationary_data['rolling_mean_20']) / stationary_data['rolling_std_20']\n",
    "    \n",
    "    # 欠損値除去\n",
    "    stationary_data = stationary_data.dropna()\n",
    "    \n",
    "    print(\"定常化データ（stationary_data）を作成しました\")\n",
    "    print(f\"データ期間: {stationary_data.index.min().date()} to {stationary_data.index.max().date()}\")\n",
    "    print(f\"データ数: {len(stationary_data)}\")\n",
    "    \n",
    "    # 最新10日間のデータ表示\n",
    "    print(\"\\n最新データ（最後の10日間）:\")\n",
    "    print(stationary_data.tail(10).round(3))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"時系列分析 総合まとめ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(\"\\n【定常性について】\")\n",
    "    if adf_result[1] <= 0.05:\n",
    "        print(\"✅ 元データは定常的 → 差分化は不要\")\n",
    "        print(\"   → レベル値での予測が可能\")\n",
    "    else:\n",
    "        print(\"❌ 元データは非定常 → 差分化が必要\")\n",
    "        print(\"   → 変化量での予測が適している\")\n",
    "    \n",
    "    print(\"\\n【モデリング結果】\")\n",
    "    if best_model is not None:\n",
    "        print(f\"最適モデル: ARIMA{best_order_aic}\")\n",
    "        print(f\"AIC: {best_aic:.2f}\")\n",
    "        print(f\"予測精度 (MAE): {mae:.3f}\")\n",
    "        print(f\"方向性精度: {directional_accuracy*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\n【トレーディングへの示唆】\")\n",
    "    \n",
    "    # 現在のスプレッド位置\n",
    "    current_spread = stationary_data['original_spread'].iloc[-1]\n",
    "    current_zscore = stationary_data['zscore'].iloc[-1]\n",
    "    \n",
    "    print(f\"現在のスプレッド: ${current_spread:.1f}\")\n",
    "    print(f\"現在のZ-score: {current_zscore:.2f}\")\n",
    "    \n",
    "    if abs(current_zscore) > 2:\n",
    "        print(\"⚠️ 極端な水準 → 逆張り戦略を検討\")\n",
    "        if current_zscore > 2:\n",
    "            print(\"   → 強いバックワーデーション（売り検討）\")\n",
    "        else:\n",
    "            print(\"   → 強いコンタンゴ（買い検討）\")\n",
    "    elif abs(current_zscore) > 1:\n",
    "        print(\"📊 やや極端な水準 → 注意深く監視\")\n",
    "    else:\n",
    "        print(\"✅ 正常範囲 → トレンドフォロー戦略\")\n",
    "    \n",
    "    # 予測精度に基づく信頼性\n",
    "    if directional_accuracy > 0.6:\n",
    "        print(f\"\\n✅ 予測精度が高い（{directional_accuracy*100:.1f}%）→ モデル信号を重視\")\n",
    "    elif directional_accuracy > 0.5:\n",
    "        print(f\"\\n📊 予測精度は中程度（{directional_accuracy*100:.1f}%）→ 他の指標と組み合わせ\")\n",
    "    else:\n",
    "        print(f\"\\n❌ 予測精度が低い（{directional_accuracy*100:.1f}%）→ モデル改善が必要\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"次のステップ: 機械学習モデルとの比較・アンサンブル\")\n",
    "    print(f\"{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
