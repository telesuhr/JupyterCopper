"""
LME Copper Data Loading Utility Module

This module provides standardized data loading functions for LME Copper analysis.
All notebooks should use this module instead of generating dummy data.

Author: LME Analysis Team
Date: 2025-07-06
"""

import pandas as pd
import psycopg2
import logging
from typing import Optional, Dict, Any, List, Tuple
import json
import os
from datetime import datetime, timedelta
import warnings

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseConnectionError(Exception):
    """Custom exception for database connection issues"""
    pass

class DataValidationError(Exception):
    """Custom exception for data validation issues"""
    pass

class LMEDataLoader:
    """
    æ¨™æº–åŒ–ã•ã‚ŒãŸLMEéŠ…ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯å…¨ã¦ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ç”¨ã•ã‚Œã‚‹æ¨™æº–çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã¯ç”Ÿæˆã›ãšã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        """
        self.connection = None
        self.config = self._load_config(config_path)
        self.table_priority = [
            'lme_copper_prices',
            'lme_copper_futures', 
            'lme_copper_spread_analysis'
        ]
        
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            "database": {
                "host": "localhost",
                "database": "lme_copper_db", 
                "user": "Yusuke",
                "port": 5432
            }
        }
    
    def get_database_connection(self) -> psycopg2.extensions.connection:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—
        
        Returns:
            psycopg2.extensions.connection: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            
        Raises:
            DatabaseConnectionError: æ¥ç¶šã«å¤±æ•—ã—ãŸå ´åˆ
        """
        if self.connection is None or self.connection.closed:
            try:
                db_config = self.config["database"]
                self.connection = psycopg2.connect(
                    host=db_config["host"],
                    database=db_config["database"],
                    user=db_config["user"],
                    port=db_config.get("port", 5432)
                )
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ: {db_config['database']}")
            except Exception as e:
                error_msg = f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"
                logger.error(error_msg)
                raise DatabaseConnectionError(error_msg)
        
        return self.connection
    
    def _check_table_exists(self, table_name: str) -> bool:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        try:
            conn = self.get_database_connection()
            cursor = conn.cursor()
            
            query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = %s
            );
            """
            cursor.execute(query, (table_name,))
            exists = cursor.fetchone()[0]
            cursor.close()
            
            logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' å­˜åœ¨ç¢ºèª: {'æœ‰' if exists else 'ç„¡'}")
            return exists
            
        except Exception as e:
            logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _get_table_info(self, table_name: str) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã®å–å¾—"""
        try:
            conn = self.get_database_connection()
            cursor = conn.cursor()
            
            # ã‚«ãƒ©ãƒ æƒ…å ±å–å¾—
            query = """
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_name = %s
            ORDER BY ordinal_position;
            """
            cursor.execute(query, (table_name,))
            columns = cursor.fetchall()
            
            # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°å–å¾—
            count_query = f"SELECT COUNT(*) FROM {table_name};"
            cursor.execute(count_query)
            record_count = cursor.fetchone()[0]
            
            # æ—¥ä»˜ç¯„å›²å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            date_range = None
            date_columns = [col[0] for col in columns if 'date' in col[0].lower()]
            if date_columns:
                date_col = date_columns[0]
                range_query = f"SELECT MIN({date_col}), MAX({date_col}) FROM {table_name};"
                cursor.execute(range_query)
                date_range = cursor.fetchone()
            
            cursor.close()
            
            return {
                'table_name': table_name,
                'columns': columns,
                'record_count': record_count,
                'date_range': date_range
            }
            
        except Exception as e:
            logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ ({table_name}): {str(e)}")
            return {}
    
    def load_cash_3m_spread_data(self, 
                                start_date: Optional[str] = None,
                                end_date: Optional[str] = None,
                                include_volume: bool = True) -> pd.DataFrame:
        """
        Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ã•ã‚ŒãŸå–å¾—
        
        Args:
            start_date: é–‹å§‹æ—¥ (YYYY-MM-DDå½¢å¼)
            end_date: çµ‚äº†æ—¥ (YYYY-MM-DDå½¢å¼)
            include_volume: å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹ã‹
            
        Returns:
            pd.DataFrame: Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿
            
        Raises:
            DataValidationError: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆ
        """
        logger.info("Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’é–‹å§‹")
        
        # æ–¹æ³•1: ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾— (CMCU0-3)
        spread_data = self._try_direct_spread_data(start_date, end_date, include_volume)
        if not spread_data.empty:
            logger.info(f"ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(spread_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return spread_data
        
        # æ–¹æ³•2: CashåŠã³3Må…ˆç‰©ã‹ã‚‰è¨ˆç®—
        calculated_spread = self._calculate_spread_from_components(start_date, end_date, include_volume)
        if not calculated_spread.empty:
            logger.info(f"è¨ˆç®—ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(calculated_spread)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return calculated_spread
        
        # æ–¹æ³•3: åŒ…æ‹¬çš„ãƒ†ãƒ¼ãƒ–ãƒ«æ¤œç´¢
        comprehensive_data = self._comprehensive_spread_search(start_date, end_date, include_volume)
        if not comprehensive_data.empty:
            logger.info(f"åŒ…æ‹¬çš„æ¤œç´¢ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(comprehensive_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return comprehensive_data
        
        # å…¨ã¦ã®æ–¹æ³•ãŒå¤±æ•—ã—ãŸå ´åˆ
        error_msg = self._generate_data_error_message("Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿", start_date, end_date)
        logger.error(error_msg)
        raise DataValidationError(error_msg)
    
    def _try_direct_spread_data(self, 
                               start_date: Optional[str], 
                               end_date: Optional[str], 
                               include_volume: bool) -> pd.DataFrame:
        """ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾— (CMCU0-3)"""
        try:
            conn = self.get_database_connection()
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã§CMCU0-3ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            for table_name in self.table_priority:
                if not self._check_table_exists(table_name):
                    continue
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«å¿œã˜ãŸã‚¯ã‚¨ãƒªæ§‹ç¯‰
                query = self._build_spread_query(table_name, 'CMCU0-3', start_date, end_date, include_volume)
                
                if query:
                    df = pd.read_sql_query(query, conn)
                    if not df.empty:
                        df = self._validate_and_clean_data(df, 'spread')
                        logger.info(f"ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ ({table_name}): {len(df)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
                        return df
            
            logger.warning("ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ (CMCU0-3) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"ç›´æ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def _calculate_spread_from_components(self, 
                                        start_date: Optional[str], 
                                        end_date: Optional[str], 
                                        include_volume: bool) -> pd.DataFrame:
        """Cashã¨Futureãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚’è¨ˆç®—"""
        try:
            # Cashãƒ‡ãƒ¼ã‚¿ã¨Futureãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cash_data = self._get_price_data('CMCU0', start_date, end_date, include_volume)
            future_data = self._get_price_data('CMCU3', start_date, end_date, include_volume)
            
            if cash_data.empty or future_data.empty:
                logger.warning("Cashã¾ãŸã¯Futureãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return pd.DataFrame()
            
            # æ—¥ä»˜ã§ãƒãƒ¼ã‚¸
            merged_data = pd.merge(
                cash_data, 
                future_data, 
                on='trade_date', 
                suffixes=('_cash', '_future'),
                how='inner'
            )
            
            if merged_data.empty:
                logger.warning("Cashã¨Futureãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ã«å¤±æ•—")
                return pd.DataFrame()
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—
            spread_data = pd.DataFrame({
                'trade_date': merged_data['trade_date'],
                'spread_value': merged_data['close_price_cash'] - merged_data['close_price_future'],
                'cash_price': merged_data['close_price_cash'],
                'future_price': merged_data['close_price_future']
            })
            
            if include_volume:
                spread_data['volume'] = merged_data.get('volume_cash', 0) + merged_data.get('volume_future', 0)
            
            spread_data = self._validate_and_clean_data(spread_data, 'spread')
            logger.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—æˆåŠŸ: {len(spread_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return spread_data
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def _comprehensive_spread_search(self, 
                                   start_date: Optional[str], 
                                   end_date: Optional[str], 
                                   include_volume: bool) -> pd.DataFrame:
        """åŒ…æ‹¬çš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿æ¤œç´¢"""
        try:
            conn = self.get_database_connection()
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã§ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            for table_name in self.table_priority:
                if not self._check_table_exists(table_name):
                    continue
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—
                table_info = self._get_table_info(table_name)
                if not table_info:
                    continue
                
                # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚«ãƒ©ãƒ ã®æ¤œç´¢
                columns = [col[0] for col in table_info['columns']]
                spread_columns = [col for col in columns if 'spread' in col.lower()]
                
                if spread_columns:
                    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒª
                    query = self._build_comprehensive_spread_query(
                        table_name, spread_columns, start_date, end_date, include_volume
                    )
                    
                    if query:
                        df = pd.read_sql_query(query, conn)
                        if not df.empty:
                            df = self._validate_and_clean_data(df, 'spread')
                            logger.info(f"åŒ…æ‹¬çš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ ({table_name}): {len(df)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
                            return df
            
            logger.warning("åŒ…æ‹¬çš„æ¤œç´¢ã§ã‚‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def load_3m_outright_price_data(self, 
                                   start_date: Optional[str] = None,
                                   end_date: Optional[str] = None,
                                   include_volume: bool = True) -> pd.DataFrame:
        """
        3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ã•ã‚ŒãŸå–å¾—
        
        Args:
            start_date: é–‹å§‹æ—¥ (YYYY-MM-DDå½¢å¼)
            end_date: çµ‚äº†æ—¥ (YYYY-MM-DDå½¢å¼)
            include_volume: å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹ã‹
            
        Returns:
            pd.DataFrame: 3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Raises:
            DataValidationError: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆ
        """
        logger.info("3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’é–‹å§‹")
        
        # CMCU3ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        price_data = self._get_price_data('CMCU3', start_date, end_date, include_volume)
        
        if not price_data.empty:
            logger.info(f"3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(price_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return price_data
        
        # å…¨ã¦ã®æ–¹æ³•ãŒå¤±æ•—ã—ãŸå ´åˆ
        error_msg = self._generate_data_error_message("3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿", start_date, end_date)
        logger.error(error_msg)
        raise DataValidationError(error_msg)
    
    def _get_price_data(self, 
                       ric_code: str, 
                       start_date: Optional[str], 
                       end_date: Optional[str], 
                       include_volume: bool) -> pd.DataFrame:
        """æŒ‡å®šã•ã‚ŒãŸRICã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            conn = self.get_database_connection()
            
            for table_name in self.table_priority:
                if not self._check_table_exists(table_name):
                    continue
                
                query = self._build_price_query(table_name, ric_code, start_date, end_date, include_volume)
                
                if query:
                    df = pd.read_sql_query(query, conn)
                    if not df.empty:
                        df = self._validate_and_clean_data(df, 'price')
                        logger.info(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ ({table_name}, {ric_code}): {len(df)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
                        return df
            
            logger.warning(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ric_code}")
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({ric_code}): {str(e)}")
            return pd.DataFrame()
    
    def _build_spread_query(self, 
                           table_name: str, 
                           ric_code: str, 
                           start_date: Optional[str], 
                           end_date: Optional[str], 
                           include_volume: bool) -> Optional[str]:
        """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ç”¨ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰"""
        try:
            table_info = self._get_table_info(table_name)
            if not table_info:
                return None
            
            columns = [col[0] for col in table_info['columns']]
            
            # åŸºæœ¬çš„ãªã‚«ãƒ©ãƒ ã®ç‰¹å®š
            date_col = self._find_date_column(columns)
            price_col = self._find_price_column(columns)
            ric_col = self._find_ric_column(columns)
            
            if not all([date_col, price_col, ric_col]):
                return None
            
            # SELECTå¥
            select_columns = [date_col, price_col]
            if include_volume:
                volume_col = self._find_volume_column(columns)
                if volume_col:
                    select_columns.append(volume_col)
            
            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = f"""
            SELECT {', '.join(select_columns)}
            FROM {table_name}
            WHERE {ric_col} = '{ric_code}'
            """
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
            if start_date:
                query += f" AND {date_col} >= '{start_date}'"
            if end_date:
                query += f" AND {date_col} <= '{end_date}'"
            
            query += f" ORDER BY {date_col};"
            
            return query
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚¯ã‚¨ãƒªæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _build_price_query(self, 
                          table_name: str, 
                          ric_code: str, 
                          start_date: Optional[str], 
                          end_date: Optional[str], 
                          include_volume: bool) -> Optional[str]:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”¨ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰"""
        try:
            table_info = self._get_table_info(table_name)
            if not table_info:
                return None
            
            columns = [col[0] for col in table_info['columns']]
            
            # åŸºæœ¬çš„ãªã‚«ãƒ©ãƒ ã®ç‰¹å®š
            date_col = self._find_date_column(columns)
            price_col = self._find_price_column(columns)
            ric_col = self._find_ric_column(columns)
            
            if not all([date_col, price_col, ric_col]):
                return None
            
            # SELECTå¥
            select_columns = [
                f"{date_col} as trade_date",
                f"{price_col} as close_price"
            ]
            
            if include_volume:
                volume_col = self._find_volume_column(columns)
                if volume_col:
                    select_columns.append(f"{volume_col} as volume")
            
            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = f"""
            SELECT {', '.join(select_columns)}
            FROM {table_name}
            WHERE {ric_col} = '{ric_code}'
            """
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
            if start_date:
                query += f" AND {date_col} >= '{start_date}'"
            if end_date:
                query += f" AND {date_col} <= '{end_date}'"
            
            query += f" ORDER BY {date_col};"
            
            return query
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼ã‚¯ã‚¨ãƒªæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _build_comprehensive_spread_query(self, 
                                        table_name: str, 
                                        spread_columns: List[str], 
                                        start_date: Optional[str], 
                                        end_date: Optional[str], 
                                        include_volume: bool) -> Optional[str]:
        """åŒ…æ‹¬çš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ç”¨ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰"""
        try:
            table_info = self._get_table_info(table_name)
            if not table_info:
                return None
            
            columns = [col[0] for col in table_info['columns']]
            
            # åŸºæœ¬çš„ãªã‚«ãƒ©ãƒ ã®ç‰¹å®š
            date_col = self._find_date_column(columns)
            
            if not date_col:
                return None
            
            # SELECTå¥
            select_columns = [f"{date_col} as trade_date"]
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            for spread_col in spread_columns:
                select_columns.append(f"{spread_col} as spread_value")
                break  # æœ€åˆã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚«ãƒ©ãƒ ã®ã¿ä½¿ç”¨
            
            if include_volume:
                volume_col = self._find_volume_column(columns)
                if volume_col:
                    select_columns.append(f"{volume_col} as volume")
            
            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = f"""
            SELECT {', '.join(select_columns)}
            FROM {table_name}
            WHERE {spread_columns[0]} IS NOT NULL
            """
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
            if start_date:
                query += f" AND {date_col} >= '{start_date}'"
            if end_date:
                query += f" AND {date_col} <= '{end_date}'"
            
            query += f" ORDER BY {date_col};"
            
            return query
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚¯ã‚¨ãƒªæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _find_date_column(self, columns: List[str]) -> Optional[str]:
        """æ—¥ä»˜ã‚«ãƒ©ãƒ ã®ç‰¹å®š"""
        date_patterns = ['trade_date', 'date', 'timestamp', 'created_date']
        for pattern in date_patterns:
            for col in columns:
                if pattern in col.lower():
                    return col
        return None
    
    def _find_price_column(self, columns: List[str]) -> Optional[str]:
        """ä¾¡æ ¼ã‚«ãƒ©ãƒ ã®ç‰¹å®š"""
        price_patterns = ['last_price', 'close_price', 'price', 'value', 'close']
        for pattern in price_patterns:
            for col in columns:
                if pattern in col.lower():
                    return col
        return None
    
    def _find_ric_column(self, columns: List[str]) -> Optional[str]:
        """RICã‚«ãƒ©ãƒ ã®ç‰¹å®š"""
        ric_patterns = ['ric_code', 'ric', 'symbol', 'instrument']
        for pattern in ric_patterns:
            for col in columns:
                if pattern in col.lower():
                    return col
        return None
    
    def _find_volume_column(self, columns: List[str]) -> Optional[str]:
        """å‡ºæ¥é«˜ã‚«ãƒ©ãƒ ã®ç‰¹å®š"""
        volume_patterns = ['volume', 'vol', 'quantity', 'size']
        for pattern in volume_patterns:
            for col in columns:
                if pattern in col.lower():
                    return col
        return None
    
    def _validate_and_clean_data(self, df: pd.DataFrame, data_type: str) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        try:
            if df.empty:
                return df
            
            # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®å‡¦ç†
            if 'trade_date' in df.columns:
                df['trade_date'] = pd.to_datetime(df['trade_date'])
                df = df.sort_values('trade_date')
            
            # æ•°å€¤ã‚«ãƒ©ãƒ ã®å‡¦ç†
            numeric_columns = df.select_dtypes(include=['number']).columns
            for col in numeric_columns:
                # ç•°å¸¸å€¤ã®é™¤å»ï¼ˆ3Ïƒç¯„å›²å¤–ï¼‰
                if len(df) > 10:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
                    mean = df[col].mean()
                    std = df[col].std()
                    if std > 0:
                        df = df[abs(df[col] - mean) <= 3 * std]
            
            # é‡è¤‡ã®é™¤å»
            if 'trade_date' in df.columns:
                df = df.drop_duplicates(subset=['trade_date'])
            
            # æ¬ æå€¤ã®å‡¦ç†
            df = df.dropna(subset=[col for col in df.columns if 'price' in col.lower() or 'value' in col.lower()])
            
            logger.info(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {len(df)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            return df
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return df
    
    def _generate_data_error_message(self, 
                                   data_type: str, 
                                   start_date: Optional[str], 
                                   end_date: Optional[str]) -> str:
        """ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆ"""
        error_msg = f"""
        ğŸš¨ {data_type}ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ

        ã€æ¤œç´¢æ¡ä»¶ã€‘
        - æœŸé–“: {start_date or 'æŒ‡å®šãªã—'} ï½ {end_date or 'æŒ‡å®šãªã—'}
        - æ¤œç´¢ãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(self.table_priority)}

        ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€‘
        1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
        2. ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
           psql -h localhost -U Yusuke -d lme_copper_db -c "\\dt"
        
        3. ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
           SELECT table_name, COUNT(*) FROM information_schema.tables 
           WHERE table_name IN ('lme_copper_prices', 'lme_copper_futures', 'lme_copper_spread_analysis') 
           GROUP BY table_name;
        
        4. ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€RICã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
           SELECT DISTINCT ric FROM lme_copper_prices LIMIT 10;

        ã€æ³¨æ„ã€‘
        ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã€‚å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚
        """
        return error_msg
    
    def get_available_data_summary(self) -> Dict[str, Any]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ã‚’å–å¾—"""
        try:
            conn = self.get_database_connection()
            summary = {
                'database_connected': True,
                'tables': {}
            }
            
            for table_name in self.table_priority:
                if self._check_table_exists(table_name):
                    table_info = self._get_table_info(table_name)
                    summary['tables'][table_name] = table_info
            
            logger.info("ãƒ‡ãƒ¼ã‚¿è¦ç´„å–å¾—æˆåŠŸ")
            return summary
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿è¦ç´„å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'database_connected': False,
                'error': str(e),
                'tables': {}
            }
    
    def close_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®ã‚¯ãƒ­ãƒ¼ã‚º"""
        if self.connection and not self.connection.closed:
            self.connection.close()
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸ")

# ä¾¿åˆ©é–¢æ•°
def create_data_loader(config_path: Optional[str] = None) -> LMEDataLoader:
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return LMEDataLoader(config_path)

def load_cash_3m_spread(start_date: Optional[str] = None, 
                       end_date: Optional[str] = None,
                       include_volume: bool = True) -> pd.DataFrame:
    """ç°¡å˜ãªCash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    loader = create_data_loader()
    try:
        return loader.load_cash_3m_spread_data(start_date, end_date, include_volume)
    finally:
        loader.close_connection()

def load_3m_outright_price(start_date: Optional[str] = None,
                          end_date: Optional[str] = None,
                          include_volume: bool = True) -> pd.DataFrame:
    """ç°¡å˜ãª3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    loader = create_data_loader()
    try:
        return loader.load_3m_outright_price_data(start_date, end_date, include_volume)
    finally:
        loader.close_connection()

def get_data_summary() -> Dict[str, Any]:
    """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¦ç´„"""
    loader = create_data_loader()
    try:
        return loader.get_available_data_summary()
    finally:
        loader.close_connection()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=== LME Data Loader ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ‡ãƒ¼ã‚¿è¦ç´„ã®å–å¾—
    summary = get_data_summary()
    print("åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿:")
    for table_name, info in summary.get('tables', {}).items():
        print(f"  {table_name}: {info.get('record_count', 0)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
    
    # Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
    try:
        spread_data = load_cash_3m_spread()
        print(f"\nCash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿: {len(spread_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        if not spread_data.empty:
            print(spread_data.head())
    except Exception as e:
        print(f"Cash/3Mã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
    try:
        price_data = load_3m_outright_price()
        print(f"\n3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿: {len(price_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        if not price_data.empty:
            print(price_data.head())
    except Exception as e:
        print(f"3Må…ˆç‰©ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")